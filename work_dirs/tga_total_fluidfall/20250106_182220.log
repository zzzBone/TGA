2025-01-06 18:22:20,096 - sim - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda-11.3
NVCC: Cuda compilation tools, release 11.3, V11.3.109
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~16.04) 9.4.0
PyTorch: 1.12.1
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1
OpenCV: 4.10.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
Simulation: 0.7.0+b4161dc
------------------------------------------------------------

2025-01-06 18:22:20,096 - sim - INFO - Distributed training: False
2025-01-06 18:22:20,210 - sim - INFO - Config:
model = dict(
    type='ParticleSimulator',
    backbone=dict(
        type='TGA',
        attr_dim=3,
        state_dim=6,
        position_dim=3,
        embed_dim=256,
        attn_dims=(256, 256),
        attn_num_heads=(8, 8),
        gat_hidden_dims=(256, 256),
        gat_num_heads=(8, 8),
        num_layers=2,
        dropouts=(0.0, 0.0),
        output_dim=256),
    head=dict(
        type='ParticleHead',
        in_channels=256,
        out_channels=3,
        seperate=False,
        rotation_dim=0,
        weighted=False,
        loss=dict(type='MSELoss', loss_weight=1.0)))
dataset_type = 'PhysicsFleXDataset'
env_cfg = dict(
    env='FluidFall',
    num_abs_token=0,
    baseline=False,
    gen_data=False,
    gen_meta=False,
    hierarchy=False,
    scene_params=[],
    eval_ratio=10000000.0,
    dataf='./data/data_FluidFall',
    n_rollout=3000,
    time_step=121,
    time_step_clip=5,
    attn_mask=8,
    dt=0.016666666666666666,
    nf_relation=300,
    nf_particle=200,
    nf_effect=200,
    train_valid_ratio=0.9,
    n_instance=1,
    n_stages=1,
    n_his=0,
    shape_state_dim=14,
    attr_dim=3,
    state_dim=6,
    position_dim=3,
    relation_dim=1,
    neighbor_radius=0.08,
    pstep=2,
    phases_dict=dict(
        instance_idx=[0, 189],
        root_num=[[]],
        instance=['fluid'],
        material=['fluid']))
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=8,
    train=dict(
        type='PhysicsFleXDataset',
        phase='train',
        env_cfg=dict(
            env='FluidFall',
            num_abs_token=0,
            baseline=False,
            gen_data=False,
            gen_meta=False,
            hierarchy=False,
            scene_params=[],
            eval_ratio=10000000.0,
            dataf='./data/data_FluidFall',
            n_rollout=3000,
            time_step=121,
            time_step_clip=5,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=1,
            n_stages=1,
            n_his=0,
            shape_state_dim=14,
            attr_dim=3,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            neighbor_radius=0.08,
            pstep=2,
            phases_dict=dict(
                instance_idx=[0, 189],
                root_num=[[]],
                instance=['fluid'],
                material=['fluid'])),
        verbose=False),
    val=dict(
        type='PhysicsFleXDataset',
        phase='valid',
        env_cfg=dict(
            env='FluidFall',
            num_abs_token=0,
            baseline=False,
            gen_data=False,
            gen_meta=False,
            hierarchy=False,
            scene_params=[],
            eval_ratio=10000000.0,
            dataf='./data/data_FluidFall',
            n_rollout=3000,
            time_step=121,
            time_step_clip=5,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=1,
            n_stages=1,
            n_his=0,
            shape_state_dim=14,
            attr_dim=3,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            neighbor_radius=0.08,
            pstep=2,
            phases_dict=dict(
                instance_idx=[0, 189],
                root_num=[[]],
                instance=['fluid'],
                material=['fluid'])),
        verbose=False),
    test=dict(
        type='PhysicsFleXDataset',
        phase='valid',
        env_cfg=dict(
            env='FluidFall',
            num_abs_token=0,
            baseline=False,
            gen_data=False,
            gen_meta=False,
            hierarchy=False,
            scene_params=[],
            eval_ratio=10000000.0,
            dataf='./data/data_FluidFall',
            n_rollout=3000,
            time_step=121,
            time_step_clip=5,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=1,
            n_stages=1,
            n_his=0,
            shape_state_dim=14,
            attr_dim=3,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            neighbor_radius=0.08,
            pstep=2,
            phases_dict=dict(
                instance_idx=[0, 189],
                root_num=[[]],
                instance=['fluid'],
                material=['fluid'])),
        verbose=False))
optimizer = dict(
    type='Adam', lr=0.0008, betas=(0.9, 0.999), weight_decay=0, amsgrad=False)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='Plateau', mode='min', factor=0.8, patience=3)
runner = dict(type='EpochBasedRunner', max_epochs=13)
checkpoint_config = dict(interval=1)
log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl', port='29513')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
find_unused_parameters = True
work_dir = 'work_dirs/tga_total_fluidfall/'
gpu_ids = range(0, 1)

2025-01-06 18:22:20,245 - sim - INFO - Model parameters: 878915
2025-01-06 18:22:20,953 - sim - INFO - Start running, host: zbl@lab601-2, work_dir: /home/zbl/sim/TIE_ECCV2022/work_dirs/tga_total_fluidfall
2025-01-06 18:22:20,953 - sim - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(NORMAL      ) MSEAccuracy                        
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) MSEAccuracy                        
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-01-06 18:22:20,954 - sim - INFO - workflow: [('train', 1)], max: 13 epochs
2025-01-06 18:22:20,954 - sim - INFO - Checkpoints will be saved to /home/zbl/sim/TIE_ECCV2022/work_dirs/tga_total_fluidfall by HardDiskBackend.
2025-01-06 18:22:27,505 - sim - INFO - Epoch [1][100/40500]	lr: 8.000e-04, eta: 9:34:37, time: 0.065, data_time: 0.050, memory: 103, loss: 9.8301, Batch std: 0.8385, Agg std: 0.9115
2025-01-06 18:22:31,308 - sim - INFO - Epoch [1][200/40500]	lr: 8.000e-04, eta: 7:34:02, time: 0.038, data_time: 0.025, memory: 103, loss: 7.0166, Batch std: 0.5881, Agg std: 0.7639
2025-01-06 18:22:35,078 - sim - INFO - Epoch [1][300/40500]	lr: 8.000e-04, eta: 6:52:49, time: 0.038, data_time: 0.025, memory: 103, loss: 6.1071, Batch std: 0.5165, Agg std: 0.6758
2025-01-06 18:22:38,800 - sim - INFO - Epoch [1][400/40500]	lr: 8.000e-04, eta: 6:31:09, time: 0.037, data_time: 0.024, memory: 103, loss: 4.8752, Batch std: 0.4501, Agg std: 0.6211
2025-01-06 18:22:42,668 - sim - INFO - Epoch [1][500/40500]	lr: 8.000e-04, eta: 6:20:40, time: 0.039, data_time: 0.026, memory: 103, loss: 4.1870, Batch std: 0.4331, Agg std: 0.5793
2025-01-06 18:22:46,422 - sim - INFO - Epoch [1][600/40500]	lr: 8.000e-04, eta: 6:12:00, time: 0.038, data_time: 0.025, memory: 103, loss: 5.4277, Batch std: 0.4643, Agg std: 0.5571
2025-01-06 18:22:50,252 - sim - INFO - Epoch [1][700/40500]	lr: 8.000e-04, eta: 6:06:44, time: 0.038, data_time: 0.026, memory: 103, loss: 4.1193, Batch std: 0.4112, Agg std: 0.5372
2025-01-06 18:22:53,912 - sim - INFO - Epoch [1][800/40500]	lr: 8.000e-04, eta: 6:00:54, time: 0.037, data_time: 0.024, memory: 103, loss: 4.9544, Batch std: 0.4510, Agg std: 0.5233
2025-01-06 18:22:57,731 - sim - INFO - Epoch [1][900/40500]	lr: 8.000e-04, eta: 5:57:55, time: 0.038, data_time: 0.025, memory: 103, loss: 5.0652, Batch std: 0.4225, Agg std: 0.5141
2025-01-06 18:23:01,496 - sim - INFO - Epoch [1][1000/40500]	lr: 8.000e-04, eta: 5:55:02, time: 0.038, data_time: 0.025, memory: 103, loss: 3.9627, Batch std: 0.4076, Agg std: 0.5026
2025-01-06 18:23:05,223 - sim - INFO - Epoch [1][1100/40500]	lr: 8.000e-04, eta: 5:52:22, time: 0.037, data_time: 0.025, memory: 103, loss: 4.2736, Batch std: 0.4363, Agg std: 0.4948
2025-01-06 18:23:09,078 - sim - INFO - Epoch [1][1200/40500]	lr: 8.000e-04, eta: 5:51:04, time: 0.039, data_time: 0.026, memory: 103, loss: 4.3969, Batch std: 0.4435, Agg std: 0.4902
2025-01-06 18:23:12,786 - sim - INFO - Epoch [1][1300/40500]	lr: 8.000e-04, eta: 5:48:57, time: 0.037, data_time: 0.024, memory: 103, loss: 5.3799, Batch std: 0.4567, Agg std: 0.4873
2025-01-06 18:23:16,615 - sim - INFO - Epoch [1][1400/40500]	lr: 8.000e-04, eta: 5:47:54, time: 0.038, data_time: 0.025, memory: 103, loss: 4.1151, Batch std: 0.4221, Agg std: 0.4841
2025-01-06 18:23:20,263 - sim - INFO - Epoch [1][1500/40500]	lr: 8.000e-04, eta: 5:45:56, time: 0.036, data_time: 0.024, memory: 103, loss: 4.5486, Batch std: 0.4236, Agg std: 0.4791
2025-01-06 18:23:24,050 - sim - INFO - Epoch [1][1600/40500]	lr: 8.000e-04, eta: 5:44:57, time: 0.038, data_time: 0.025, memory: 103, loss: 5.2313, Batch std: 0.4649, Agg std: 0.4777
2025-01-06 18:23:27,780 - sim - INFO - Epoch [1][1700/40500]	lr: 8.000e-04, eta: 5:43:47, time: 0.037, data_time: 0.025, memory: 103, loss: 4.2630, Batch std: 0.4188, Agg std: 0.4754
2025-01-06 18:23:31,596 - sim - INFO - Epoch [1][1800/40500]	lr: 8.000e-04, eta: 5:43:10, time: 0.038, data_time: 0.025, memory: 103, loss: 4.6726, Batch std: 0.4256, Agg std: 0.4716
2025-01-06 18:23:35,284 - sim - INFO - Epoch [1][1900/40500]	lr: 8.000e-04, eta: 5:42:00, time: 0.037, data_time: 0.024, memory: 103, loss: 4.3613, Batch std: 0.4152, Agg std: 0.4691
2025-01-06 18:23:39,108 - sim - INFO - Epoch [1][2000/40500]	lr: 8.000e-04, eta: 5:41:33, time: 0.038, data_time: 0.025, memory: 103, loss: 5.0818, Batch std: 0.4396, Agg std: 0.4673
2025-01-06 18:23:42,729 - sim - INFO - Epoch [1][2100/40500]	lr: 8.000e-04, eta: 5:40:18, time: 0.036, data_time: 0.023, memory: 103, loss: 3.8233, Batch std: 0.4031, Agg std: 0.4648
2025-01-06 18:23:46,569 - sim - INFO - Epoch [1][2200/40500]	lr: 8.000e-04, eta: 5:40:01, time: 0.038, data_time: 0.026, memory: 103, loss: 4.1142, Batch std: 0.3982, Agg std: 0.4617
2025-01-06 18:23:50,207 - sim - INFO - Epoch [1][2300/40500]	lr: 8.000e-04, eta: 5:38:59, time: 0.036, data_time: 0.024, memory: 103, loss: 3.6392, Batch std: 0.3802, Agg std: 0.4587
2025-01-06 18:23:54,054 - sim - INFO - Epoch [1][2400/40500]	lr: 8.000e-04, eta: 5:38:48, time: 0.038, data_time: 0.026, memory: 103, loss: 4.6819, Batch std: 0.4215, Agg std: 0.4562
2025-01-06 18:23:57,695 - sim - INFO - Epoch [1][2500/40500]	lr: 8.000e-04, eta: 5:37:54, time: 0.036, data_time: 0.023, memory: 103, loss: 4.6193, Batch std: 0.4185, Agg std: 0.4545
2025-01-06 18:24:01,533 - sim - INFO - Epoch [1][2600/40500]	lr: 8.000e-04, eta: 5:37:44, time: 0.038, data_time: 0.026, memory: 103, loss: 5.6627, Batch std: 0.4604, Agg std: 0.4545
2025-01-06 18:24:05,169 - sim - INFO - Epoch [1][2700/40500]	lr: 8.000e-04, eta: 5:36:55, time: 0.036, data_time: 0.024, memory: 103, loss: 4.2265, Batch std: 0.4060, Agg std: 0.4532
2025-01-06 18:24:08,994 - sim - INFO - Epoch [1][2800/40500]	lr: 8.000e-04, eta: 5:36:45, time: 0.038, data_time: 0.025, memory: 103, loss: 3.5286, Batch std: 0.3890, Agg std: 0.4512
2025-01-06 18:24:12,638 - sim - INFO - Epoch [1][2900/40500]	lr: 8.000e-04, eta: 5:36:02, time: 0.036, data_time: 0.024, memory: 103, loss: 3.3622, Batch std: 0.3790, Agg std: 0.4489
2025-01-06 18:24:16,451 - sim - INFO - Epoch [1][3000/40500]	lr: 8.000e-04, eta: 5:35:52, time: 0.038, data_time: 0.025, memory: 103, loss: 4.6661, Batch std: 0.4083, Agg std: 0.4471
2025-01-06 18:24:20,099 - sim - INFO - Epoch [1][3100/40500]	lr: 8.000e-04, eta: 5:35:14, time: 0.036, data_time: 0.024, memory: 103, loss: 5.1200, Batch std: 0.4122, Agg std: 0.4457
2025-01-06 18:24:23,924 - sim - INFO - Epoch [1][3200/40500]	lr: 8.000e-04, eta: 5:35:07, time: 0.038, data_time: 0.025, memory: 103, loss: 4.2466, Batch std: 0.4172, Agg std: 0.4449
2025-01-06 18:24:27,553 - sim - INFO - Epoch [1][3300/40500]	lr: 8.000e-04, eta: 5:34:29, time: 0.036, data_time: 0.024, memory: 103, loss: 4.7382, Batch std: 0.4158, Agg std: 0.4440
2025-01-06 18:24:31,373 - sim - INFO - Epoch [1][3400/40500]	lr: 8.000e-04, eta: 5:34:23, time: 0.038, data_time: 0.025, memory: 103, loss: 4.5795, Batch std: 0.4276, Agg std: 0.4434
2025-01-06 18:24:35,011 - sim - INFO - Epoch [1][3500/40500]	lr: 8.000e-04, eta: 5:33:50, time: 0.036, data_time: 0.024, memory: 103, loss: 4.1900, Batch std: 0.3987, Agg std: 0.4426
2025-01-06 18:24:38,826 - sim - INFO - Epoch [1][3600/40500]	lr: 8.000e-04, eta: 5:33:44, time: 0.038, data_time: 0.025, memory: 103, loss: 4.7093, Batch std: 0.4238, Agg std: 0.4417
2025-01-06 18:24:42,468 - sim - INFO - Epoch [1][3700/40500]	lr: 8.000e-04, eta: 5:33:13, time: 0.036, data_time: 0.024, memory: 103, loss: 4.4194, Batch std: 0.4045, Agg std: 0.4409
2025-01-06 18:24:46,195 - sim - INFO - Epoch [1][3800/40500]	lr: 8.000e-04, eta: 5:32:56, time: 0.037, data_time: 0.025, memory: 103, loss: 4.4179, Batch std: 0.4172, Agg std: 0.4399
2025-01-06 18:24:49,899 - sim - INFO - Epoch [1][3900/40500]	lr: 8.000e-04, eta: 5:32:36, time: 0.037, data_time: 0.024, memory: 103, loss: 4.5271, Batch std: 0.4211, Agg std: 0.4395
2025-01-06 18:24:53,744 - sim - INFO - Epoch [1][4000/40500]	lr: 8.000e-04, eta: 5:32:36, time: 0.038, data_time: 0.026, memory: 103, loss: 4.2692, Batch std: 0.4032, Agg std: 0.4389
2025-01-06 18:24:57,434 - sim - INFO - Epoch [1][4100/40500]	lr: 8.000e-04, eta: 5:32:15, time: 0.037, data_time: 0.024, memory: 103, loss: 3.5453, Batch std: 0.3893, Agg std: 0.4378
2025-01-06 18:25:01,246 - sim - INFO - Epoch [1][4200/40500]	lr: 8.000e-04, eta: 5:32:11, time: 0.038, data_time: 0.025, memory: 103, loss: 4.1887, Batch std: 0.3944, Agg std: 0.4367
2025-01-06 18:25:04,890 - sim - INFO - Epoch [1][4300/40500]	lr: 8.000e-04, eta: 5:31:46, time: 0.036, data_time: 0.024, memory: 103, loss: 4.3379, Batch std: 0.4155, Agg std: 0.4359
2025-01-06 18:25:08,751 - sim - INFO - Epoch [1][4400/40500]	lr: 8.000e-04, eta: 5:31:48, time: 0.039, data_time: 0.026, memory: 103, loss: 4.8865, Batch std: 0.4153, Agg std: 0.4355
2025-01-06 18:25:12,414 - sim - INFO - Epoch [1][4500/40500]	lr: 8.000e-04, eta: 5:31:27, time: 0.037, data_time: 0.024, memory: 103, loss: 4.2895, Batch std: 0.4138, Agg std: 0.4349
2025-01-06 18:25:16,259 - sim - INFO - Epoch [1][4600/40500]	lr: 8.000e-04, eta: 5:31:27, time: 0.038, data_time: 0.026, memory: 103, loss: 4.0792, Batch std: 0.4003, Agg std: 0.4342
2025-01-06 18:25:19,888 - sim - INFO - Epoch [1][4700/40500]	lr: 8.000e-04, eta: 5:31:03, time: 0.036, data_time: 0.023, memory: 103, loss: 4.7770, Batch std: 0.4141, Agg std: 0.4338
2025-01-06 18:25:23,735 - sim - INFO - Epoch [1][4800/40500]	lr: 8.000e-04, eta: 5:31:04, time: 0.038, data_time: 0.026, memory: 103, loss: 3.5045, Batch std: 0.3843, Agg std: 0.4331
2025-01-06 18:25:27,354 - sim - INFO - Epoch [1][4900/40500]	lr: 8.000e-04, eta: 5:30:40, time: 0.036, data_time: 0.023, memory: 103, loss: 4.0343, Batch std: 0.4008, Agg std: 0.4322
2025-01-06 18:25:31,190 - sim - INFO - Epoch [1][5000/40500]	lr: 8.000e-04, eta: 5:30:39, time: 0.038, data_time: 0.025, memory: 103, loss: 4.1588, Batch std: 0.3969, Agg std: 0.4314
2025-01-06 18:25:34,833 - sim - INFO - Epoch [1][5100/40500]	lr: 8.000e-04, eta: 5:30:19, time: 0.036, data_time: 0.024, memory: 103, loss: 4.7908, Batch std: 0.4135, Agg std: 0.4310
2025-01-06 18:25:38,668 - sim - INFO - Epoch [1][5200/40500]	lr: 8.000e-04, eta: 5:30:19, time: 0.038, data_time: 0.026, memory: 103, loss: 4.5902, Batch std: 0.3981, Agg std: 0.4305
2025-01-06 18:25:42,317 - sim - INFO - Epoch [1][5300/40500]	lr: 8.000e-04, eta: 5:30:00, time: 0.036, data_time: 0.023, memory: 103, loss: 3.7416, Batch std: 0.3853, Agg std: 0.4298
2025-01-06 18:25:46,150 - sim - INFO - Epoch [1][5400/40500]	lr: 8.000e-04, eta: 5:29:59, time: 0.038, data_time: 0.025, memory: 103, loss: 3.6003, Batch std: 0.3911, Agg std: 0.4289
2025-01-06 18:25:49,763 - sim - INFO - Epoch [1][5500/40500]	lr: 8.000e-04, eta: 5:29:38, time: 0.036, data_time: 0.023, memory: 103, loss: 4.1265, Batch std: 0.4058, Agg std: 0.4284
2025-01-06 18:25:53,619 - sim - INFO - Epoch [1][5600/40500]	lr: 8.000e-04, eta: 5:29:39, time: 0.039, data_time: 0.026, memory: 103, loss: 4.4980, Batch std: 0.4178, Agg std: 0.4283
2025-01-06 18:25:57,257 - sim - INFO - Epoch [1][5700/40500]	lr: 8.000e-04, eta: 5:29:21, time: 0.036, data_time: 0.023, memory: 103, loss: 4.7977, Batch std: 0.4187, Agg std: 0.4279
2025-01-06 18:26:01,084 - sim - INFO - Epoch [1][5800/40500]	lr: 8.000e-04, eta: 5:29:20, time: 0.038, data_time: 0.026, memory: 103, loss: 3.9556, Batch std: 0.3953, Agg std: 0.4276
2025-01-06 18:26:04,723 - sim - INFO - Epoch [1][5900/40500]	lr: 8.000e-04, eta: 5:29:03, time: 0.036, data_time: 0.024, memory: 103, loss: 3.9356, Batch std: 0.4109, Agg std: 0.4273
2025-01-06 18:26:08,541 - sim - INFO - Epoch [1][6000/40500]	lr: 8.000e-04, eta: 5:29:01, time: 0.038, data_time: 0.025, memory: 103, loss: 4.5167, Batch std: 0.4078, Agg std: 0.4269
2025-01-06 18:26:12,157 - sim - INFO - Epoch [1][6100/40500]	lr: 8.000e-04, eta: 5:28:42, time: 0.036, data_time: 0.023, memory: 103, loss: 3.4114, Batch std: 0.3742, Agg std: 0.4264
2025-01-06 18:26:15,984 - sim - INFO - Epoch [1][6200/40500]	lr: 8.000e-04, eta: 5:28:41, time: 0.038, data_time: 0.025, memory: 103, loss: 4.2921, Batch std: 0.4152, Agg std: 0.4258
2025-01-06 18:26:19,631 - sim - INFO - Epoch [1][6300/40500]	lr: 8.000e-04, eta: 5:28:26, time: 0.036, data_time: 0.024, memory: 103, loss: 4.5721, Batch std: 0.3957, Agg std: 0.4255
2025-01-06 18:26:23,452 - sim - INFO - Epoch [1][6400/40500]	lr: 8.000e-04, eta: 5:28:24, time: 0.038, data_time: 0.025, memory: 103, loss: 4.7799, Batch std: 0.4048, Agg std: 0.4250
2025-01-06 18:26:27,088 - sim - INFO - Epoch [1][6500/40500]	lr: 8.000e-04, eta: 5:28:08, time: 0.036, data_time: 0.024, memory: 103, loss: 4.2275, Batch std: 0.3998, Agg std: 0.4247
2025-01-06 18:26:30,899 - sim - INFO - Epoch [1][6600/40500]	lr: 8.000e-04, eta: 5:28:07, time: 0.038, data_time: 0.025, memory: 103, loss: 4.3710, Batch std: 0.4096, Agg std: 0.4243
2025-01-06 18:26:34,561 - sim - INFO - Epoch [1][6700/40500]	lr: 8.000e-04, eta: 5:27:53, time: 0.037, data_time: 0.024, memory: 103, loss: 5.4743, Batch std: 0.4298, Agg std: 0.4244
2025-01-06 18:26:38,356 - sim - INFO - Epoch [1][6800/40500]	lr: 8.000e-04, eta: 5:27:50, time: 0.038, data_time: 0.025, memory: 103, loss: 4.4176, Batch std: 0.4059, Agg std: 0.4242

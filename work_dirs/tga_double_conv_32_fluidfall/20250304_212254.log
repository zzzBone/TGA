2025-03-04 21:22:54,321 - sim - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda-11.3
NVCC: Cuda compilation tools, release 11.3, V11.3.109
GCC: gcc (Ubuntu 6.5.0-2ubuntu1~16.04) 6.5.0 20181026
PyTorch: 1.12.1
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1
OpenCV: 4.10.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
Simulation: 0.7.0+1227d7e
------------------------------------------------------------

2025-03-04 21:22:54,321 - sim - INFO - Distributed training: False
2025-03-04 21:22:54,434 - sim - INFO - Config:
model = dict(
    type='ParticleSimulator',
    backbone=dict(
        type='TGA',
        attr_dim=3,
        state_dim=6,
        position_dim=3,
        embed_dim=32,
        attn_dims=(32, 32),
        attn_num_heads=(8, 8),
        gat_hidden_dims=(32, 32),
        gat_num_heads=(8, 8),
        num_layers=1,
        dropouts=(0.2, 0.2),
        output_dim=32,
        num_abs_token=2),
    head=dict(
        type='ParticleHead',
        in_channels=32,
        out_channels=3,
        seperate=False,
        rotation_dim=0,
        weighted=False,
        loss=dict(type='MSELoss', loss_weight=1.0)))
dataset_type = 'PhysicsFleXDataset'
env_cfg = dict(
    env='FluidFall',
    num_abs_token=0,
    baseline=False,
    gen_data=False,
    gen_meta=False,
    hierarchy=False,
    scene_params=[],
    eval_ratio=10000000.0,
    dataf='./data/data_FluidFall',
    n_rollout=3000,
    time_step=121,
    time_step_clip=5,
    attn_mask=8,
    dt=0.016666666666666666,
    nf_relation=300,
    nf_particle=200,
    nf_effect=200,
    train_valid_ratio=0.9,
    n_instance=1,
    n_stages=1,
    n_his=0,
    shape_state_dim=14,
    attr_dim=3,
    state_dim=6,
    position_dim=3,
    relation_dim=1,
    neighbor_radius=0.08,
    pstep=2,
    phases_dict=dict(
        instance_idx=[0, 189],
        root_num=[[]],
        instance=['fluid'],
        material=['fluid']))
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=8,
    train=dict(
        type='PhysicsFleXDataset',
        phase='train',
        env_cfg=dict(
            env='FluidFall',
            num_abs_token=2,
            baseline=False,
            gen_data=False,
            gen_meta=False,
            hierarchy=False,
            scene_params=[],
            eval_ratio=10000000.0,
            dataf='./data/data_FluidFall',
            n_rollout=3000,
            time_step=121,
            time_step_clip=5,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=1,
            n_stages=1,
            n_his=0,
            shape_state_dim=14,
            attr_dim=3,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            neighbor_radius=0.08,
            pstep=2,
            phases_dict=dict(
                instance_idx=[0, 189],
                root_num=[[]],
                instance=['fluid'],
                material=['fluid'])),
        verbose=False),
    val=dict(
        type='PhysicsFleXDataset',
        phase='valid',
        env_cfg=dict(
            env='FluidFall',
            num_abs_token=2,
            baseline=False,
            gen_data=False,
            gen_meta=False,
            hierarchy=False,
            scene_params=[],
            eval_ratio=10000000.0,
            dataf='./data/data_FluidFall',
            n_rollout=3000,
            time_step=121,
            time_step_clip=5,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=1,
            n_stages=1,
            n_his=0,
            shape_state_dim=14,
            attr_dim=3,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            neighbor_radius=0.08,
            pstep=2,
            phases_dict=dict(
                instance_idx=[0, 189],
                root_num=[[]],
                instance=['fluid'],
                material=['fluid'])),
        verbose=False),
    test=dict(
        type='PhysicsFleXDataset',
        phase='valid',
        env_cfg=dict(
            env='FluidFall',
            num_abs_token=2,
            baseline=False,
            gen_data=False,
            gen_meta=False,
            hierarchy=False,
            scene_params=[],
            eval_ratio=10000000.0,
            dataf='./data/data_FluidFall',
            n_rollout=3000,
            time_step=121,
            time_step_clip=5,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=1,
            n_stages=1,
            n_his=0,
            shape_state_dim=14,
            attr_dim=3,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            neighbor_radius=0.08,
            pstep=2,
            phases_dict=dict(
                instance_idx=[0, 189],
                root_num=[[]],
                instance=['fluid'],
                material=['fluid'])),
        verbose=False))
optimizer = dict(
    type='Adam', lr=0.0008, betas=(0.9, 0.999), weight_decay=0, amsgrad=False)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='Plateau', mode='min', factor=0.8, patience=3)
runner = dict(type='EpochBasedRunner', max_epochs=13)
checkpoint_config = dict(interval=1)
log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl', port='29513')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
find_unused_parameters = True
num_abs_token = 2
work_dir = 'work_dirs/tga_res_32_fluidfall'
gpu_ids = range(0, 1)

2025-03-04 21:22:54,485 - sim - INFO - Model parameters: 59198
2025-03-04 21:22:55,222 - sim - INFO - Start running, host: zbl@lab601-2, work_dir: /home/zbl/sim/TIE_ECCV2022/work_dirs/tga_res_32_fluidfall
2025-03-04 21:22:55,222 - sim - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(NORMAL      ) MSEAccuracy                        
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) MSEAccuracy                        
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-03-04 21:22:55,223 - sim - INFO - workflow: [('train', 1)], max: 13 epochs
2025-03-04 21:22:55,223 - sim - INFO - Checkpoints will be saved to /home/zbl/sim/TIE_ECCV2022/work_dirs/tga_res_32_fluidfall by HardDiskBackend.
2025-03-04 21:23:02,719 - sim - INFO - Epoch [1][100/40500]	lr: 8.000e-04, eta: 10:57:30, time: 0.075, data_time: 0.039, memory: 360, loss: 0.3792, Batch std: 0.5241, Agg std: 0.6651
2025-03-04 21:23:06,719 - sim - INFO - Epoch [1][200/40500]	lr: 8.000e-04, eta: 8:24:07, time: 0.040, data_time: 0.012, memory: 360, loss: 0.2154, Batch std: 0.4056, Agg std: 0.4879
2025-03-04 21:23:10,700 - sim - INFO - Epoch [1][300/40500]	lr: 8.000e-04, eta: 7:32:22, time: 0.040, data_time: 0.012, memory: 360, loss: 0.2052, Batch std: 0.3881, Agg std: 0.4488
2025-03-04 21:23:14,702 - sim - INFO - Epoch [1][400/40500]	lr: 8.000e-04, eta: 7:06:55, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1908, Batch std: 0.3766, Agg std: 0.4302
2025-03-04 21:23:18,606 - sim - INFO - Epoch [1][500/40500]	lr: 8.000e-04, eta: 6:49:55, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1814, Batch std: 0.3653, Agg std: 0.4180
2025-03-04 21:23:22,612 - sim - INFO - Epoch [1][600/40500]	lr: 8.000e-04, eta: 6:40:03, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1965, Batch std: 0.3793, Agg std: 0.4092
2025-03-04 21:23:26,627 - sim - INFO - Epoch [1][700/40500]	lr: 8.000e-04, eta: 6:33:05, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1839, Batch std: 0.3713, Agg std: 0.4035
2025-03-04 21:23:30,596 - sim - INFO - Epoch [1][800/40500]	lr: 8.000e-04, eta: 6:27:21, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1717, Batch std: 0.3583, Agg std: 0.3981
2025-03-04 21:23:34,635 - sim - INFO - Epoch [1][900/40500]	lr: 8.000e-04, eta: 6:23:33, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1851, Batch std: 0.3672, Agg std: 0.3945
2025-03-04 21:23:38,503 - sim - INFO - Epoch [1][1000/40500]	lr: 8.000e-04, eta: 6:19:00, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1953, Batch std: 0.3757, Agg std: 0.3919
2025-03-04 21:23:42,520 - sim - INFO - Epoch [1][1100/40500]	lr: 8.000e-04, eta: 6:16:28, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1777, Batch std: 0.3600, Agg std: 0.3896
2025-03-04 21:23:46,450 - sim - INFO - Epoch [1][1200/40500]	lr: 8.000e-04, eta: 6:13:42, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1747, Batch std: 0.3592, Agg std: 0.3873
2025-03-04 21:23:50,470 - sim - INFO - Epoch [1][1300/40500]	lr: 8.000e-04, eta: 6:11:57, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1714, Batch std: 0.3591, Agg std: 0.3850
2025-03-04 21:23:54,350 - sim - INFO - Epoch [1][1400/40500]	lr: 8.000e-04, eta: 6:09:34, time: 0.039, data_time: 0.011, memory: 360, loss: 0.2082, Batch std: 0.3872, Agg std: 0.3838
2025-03-04 21:23:58,278 - sim - INFO - Epoch [1][1500/40500]	lr: 8.000e-04, eta: 6:07:46, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1847, Batch std: 0.3700, Agg std: 0.3837
2025-03-04 21:24:02,269 - sim - INFO - Epoch [1][1600/40500]	lr: 8.000e-04, eta: 6:06:32, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1783, Batch std: 0.3605, Agg std: 0.3826
2025-03-04 21:24:06,192 - sim - INFO - Epoch [1][1700/40500]	lr: 8.000e-04, eta: 6:05:06, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1719, Batch std: 0.3552, Agg std: 0.3809
2025-03-04 21:24:10,208 - sim - INFO - Epoch [1][1800/40500]	lr: 8.000e-04, eta: 6:04:15, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1636, Batch std: 0.3470, Agg std: 0.3793
2025-03-04 21:24:14,164 - sim - INFO - Epoch [1][1900/40500]	lr: 8.000e-04, eta: 6:03:13, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1663, Batch std: 0.3481, Agg std: 0.3776
2025-03-04 21:24:18,118 - sim - INFO - Epoch [1][2000/40500]	lr: 8.000e-04, eta: 6:02:16, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1654, Batch std: 0.3505, Agg std: 0.3759
2025-03-04 21:24:22,229 - sim - INFO - Epoch [1][2100/40500]	lr: 8.000e-04, eta: 6:02:04, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1690, Batch std: 0.3565, Agg std: 0.3749
2025-03-04 21:24:26,195 - sim - INFO - Epoch [1][2200/40500]	lr: 8.000e-04, eta: 6:01:17, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1695, Batch std: 0.3542, Agg std: 0.3741
2025-03-04 21:24:30,185 - sim - INFO - Epoch [1][2300/40500]	lr: 8.000e-04, eta: 6:00:40, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1578, Batch std: 0.3436, Agg std: 0.3729
2025-03-04 21:24:34,085 - sim - INFO - Epoch [1][2400/40500]	lr: 8.000e-04, eta: 5:59:46, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1748, Batch std: 0.3579, Agg std: 0.3721
2025-03-04 21:24:38,131 - sim - INFO - Epoch [1][2500/40500]	lr: 8.000e-04, eta: 5:59:27, time: 0.040, data_time: 0.013, memory: 360, loss: 0.1677, Batch std: 0.3496, Agg std: 0.3713
2025-03-04 21:24:42,123 - sim - INFO - Epoch [1][2600/40500]	lr: 8.000e-04, eta: 5:58:57, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1701, Batch std: 0.3537, Agg std: 0.3703
2025-03-04 21:24:46,144 - sim - INFO - Epoch [1][2700/40500]	lr: 8.000e-04, eta: 5:58:36, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1682, Batch std: 0.3552, Agg std: 0.3700
2025-03-04 21:24:50,166 - sim - INFO - Epoch [1][2800/40500]	lr: 8.000e-04, eta: 5:58:15, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1673, Batch std: 0.3512, Agg std: 0.3694
2025-03-04 21:24:54,095 - sim - INFO - Epoch [1][2900/40500]	lr: 8.000e-04, eta: 5:57:40, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1574, Batch std: 0.3404, Agg std: 0.3685
2025-03-04 21:24:58,134 - sim - INFO - Epoch [1][3000/40500]	lr: 8.000e-04, eta: 5:57:25, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1549, Batch std: 0.3375, Agg std: 0.3675
2025-03-04 21:25:02,153 - sim - INFO - Epoch [1][3100/40500]	lr: 8.000e-04, eta: 5:57:08, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1622, Batch std: 0.3488, Agg std: 0.3665
2025-03-04 21:25:06,228 - sim - INFO - Epoch [1][3200/40500]	lr: 8.000e-04, eta: 5:57:01, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1671, Batch std: 0.3550, Agg std: 0.3663
2025-03-04 21:25:10,157 - sim - INFO - Epoch [1][3300/40500]	lr: 8.000e-04, eta: 5:56:30, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1568, Batch std: 0.3396, Agg std: 0.3657
2025-03-04 21:25:14,252 - sim - INFO - Epoch [1][3400/40500]	lr: 8.000e-04, eta: 5:56:27, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1696, Batch std: 0.3532, Agg std: 0.3650
2025-03-04 21:25:18,270 - sim - INFO - Epoch [1][3500/40500]	lr: 8.000e-04, eta: 5:56:12, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1668, Batch std: 0.3486, Agg std: 0.3646
2025-03-04 21:25:22,330 - sim - INFO - Epoch [1][3600/40500]	lr: 8.000e-04, eta: 5:56:04, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1780, Batch std: 0.3630, Agg std: 0.3644
2025-03-04 21:25:26,438 - sim - INFO - Epoch [1][3700/40500]	lr: 8.000e-04, eta: 5:56:03, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1638, Batch std: 0.3515, Agg std: 0.3641
2025-03-04 21:25:30,461 - sim - INFO - Epoch [1][3800/40500]	lr: 8.000e-04, eta: 5:55:50, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1559, Batch std: 0.3430, Agg std: 0.3636
2025-03-04 21:25:34,381 - sim - INFO - Epoch [1][3900/40500]	lr: 8.000e-04, eta: 5:55:24, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1612, Batch std: 0.3480, Agg std: 0.3632
2025-03-04 21:25:38,431 - sim - INFO - Epoch [1][4000/40500]	lr: 8.000e-04, eta: 5:55:16, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1630, Batch std: 0.3467, Agg std: 0.3628
2025-03-04 21:25:42,590 - sim - INFO - Epoch [1][4100/40500]	lr: 8.000e-04, eta: 5:55:22, time: 0.042, data_time: 0.014, memory: 360, loss: 0.1694, Batch std: 0.3558, Agg std: 0.3626
2025-03-04 21:25:46,553 - sim - INFO - Epoch [1][4200/40500]	lr: 8.000e-04, eta: 5:55:03, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1509, Batch std: 0.3354, Agg std: 0.3621
2025-03-04 21:25:50,556 - sim - INFO - Epoch [1][4300/40500]	lr: 8.000e-04, eta: 5:54:50, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1650, Batch std: 0.3480, Agg std: 0.3616
2025-03-04 21:25:54,541 - sim - INFO - Epoch [1][4400/40500]	lr: 8.000e-04, eta: 5:54:35, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1660, Batch std: 0.3517, Agg std: 0.3614
2025-03-04 21:25:58,611 - sim - INFO - Epoch [1][4500/40500]	lr: 8.000e-04, eta: 5:54:30, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1613, Batch std: 0.3455, Agg std: 0.3611
2025-03-04 21:26:02,612 - sim - INFO - Epoch [1][4600/40500]	lr: 8.000e-04, eta: 5:54:18, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1642, Batch std: 0.3544, Agg std: 0.3608
2025-03-04 21:26:06,654 - sim - INFO - Epoch [1][4700/40500]	lr: 8.000e-04, eta: 5:54:10, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1734, Batch std: 0.3564, Agg std: 0.3607
2025-03-04 21:26:10,741 - sim - INFO - Epoch [1][4800/40500]	lr: 8.000e-04, eta: 5:54:08, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1535, Batch std: 0.3372, Agg std: 0.3605
2025-03-04 21:26:14,676 - sim - INFO - Epoch [1][4900/40500]	lr: 8.000e-04, eta: 5:53:49, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1562, Batch std: 0.3451, Agg std: 0.3601
2025-03-04 21:26:18,730 - sim - INFO - Epoch [1][5000/40500]	lr: 8.000e-04, eta: 5:53:43, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1598, Batch std: 0.3463, Agg std: 0.3597
2025-03-04 21:26:22,826 - sim - INFO - Epoch [1][5100/40500]	lr: 8.000e-04, eta: 5:53:42, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1643, Batch std: 0.3524, Agg std: 0.3595
2025-03-04 21:26:26,773 - sim - INFO - Epoch [1][5200/40500]	lr: 8.000e-04, eta: 5:53:25, time: 0.039, data_time: 0.012, memory: 360, loss: 0.1762, Batch std: 0.3637, Agg std: 0.3595
2025-03-04 21:26:30,757 - sim - INFO - Epoch [1][5300/40500]	lr: 8.000e-04, eta: 5:53:13, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1465, Batch std: 0.3294, Agg std: 0.3593
2025-03-04 21:26:34,698 - sim - INFO - Epoch [1][5400/40500]	lr: 8.000e-04, eta: 5:52:57, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1606, Batch std: 0.3481, Agg std: 0.3589
2025-03-04 21:26:38,818 - sim - INFO - Epoch [1][5500/40500]	lr: 8.000e-04, eta: 5:52:58, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1588, Batch std: 0.3419, Agg std: 0.3586
2025-03-04 21:26:42,831 - sim - INFO - Epoch [1][5600/40500]	lr: 8.000e-04, eta: 5:52:49, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1591, Batch std: 0.3421, Agg std: 0.3583
2025-03-04 21:26:46,939 - sim - INFO - Epoch [1][5700/40500]	lr: 8.000e-04, eta: 5:52:49, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1573, Batch std: 0.3377, Agg std: 0.3580
2025-03-04 21:26:50,923 - sim - INFO - Epoch [1][5800/40500]	lr: 8.000e-04, eta: 5:52:37, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1575, Batch std: 0.3434, Agg std: 0.3577
2025-03-04 21:26:55,030 - sim - INFO - Epoch [1][5900/40500]	lr: 8.000e-04, eta: 5:52:37, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1508, Batch std: 0.3383, Agg std: 0.3574
2025-03-04 21:26:58,965 - sim - INFO - Epoch [1][6000/40500]	lr: 8.000e-04, eta: 5:52:22, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1695, Batch std: 0.3557, Agg std: 0.3573
2025-03-04 21:27:02,949 - sim - INFO - Epoch [1][6100/40500]	lr: 8.000e-04, eta: 5:52:11, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1564, Batch std: 0.3448, Agg std: 0.3572
2025-03-04 21:27:06,971 - sim - INFO - Epoch [1][6200/40500]	lr: 8.000e-04, eta: 5:52:04, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1740, Batch std: 0.3588, Agg std: 0.3571
2025-03-04 21:27:11,054 - sim - INFO - Epoch [1][6300/40500]	lr: 8.000e-04, eta: 5:52:02, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1561, Batch std: 0.3410, Agg std: 0.3569
2025-03-04 21:27:15,087 - sim - INFO - Epoch [1][6400/40500]	lr: 8.000e-04, eta: 5:51:55, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1622, Batch std: 0.3447, Agg std: 0.3567
2025-03-04 21:27:19,051 - sim - INFO - Epoch [1][6500/40500]	lr: 8.000e-04, eta: 5:51:43, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1606, Batch std: 0.3462, Agg std: 0.3566
2025-03-04 21:27:23,301 - sim - INFO - Epoch [1][6600/40500]	lr: 8.000e-04, eta: 5:51:54, time: 0.043, data_time: 0.015, memory: 360, loss: 0.1669, Batch std: 0.3491, Agg std: 0.3564
2025-03-04 21:27:27,310 - sim - INFO - Epoch [1][6700/40500]	lr: 8.000e-04, eta: 5:51:46, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1624, Batch std: 0.3471, Agg std: 0.3563
2025-03-04 21:27:31,314 - sim - INFO - Epoch [1][6800/40500]	lr: 8.000e-04, eta: 5:51:38, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1622, Batch std: 0.3453, Agg std: 0.3561
2025-03-04 21:27:35,388 - sim - INFO - Epoch [1][6900/40500]	lr: 8.000e-04, eta: 5:51:35, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1556, Batch std: 0.3438, Agg std: 0.3560
2025-03-04 21:27:39,340 - sim - INFO - Epoch [1][7000/40500]	lr: 8.000e-04, eta: 5:51:23, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1625, Batch std: 0.3473, Agg std: 0.3558
2025-03-04 21:27:43,490 - sim - INFO - Epoch [1][7100/40500]	lr: 8.000e-04, eta: 5:51:25, time: 0.041, data_time: 0.014, memory: 360, loss: 0.1499, Batch std: 0.3356, Agg std: 0.3556
2025-03-04 21:27:47,429 - sim - INFO - Epoch [1][7200/40500]	lr: 8.000e-04, eta: 5:51:13, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1648, Batch std: 0.3495, Agg std: 0.3554
2025-03-04 21:27:51,490 - sim - INFO - Epoch [1][7300/40500]	lr: 8.000e-04, eta: 5:51:09, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1574, Batch std: 0.3459, Agg std: 0.3553
2025-03-04 21:27:55,458 - sim - INFO - Epoch [1][7400/40500]	lr: 8.000e-04, eta: 5:50:58, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1579, Batch std: 0.3449, Agg std: 0.3552
2025-03-04 21:27:59,412 - sim - INFO - Epoch [1][7500/40500]	lr: 8.000e-04, eta: 5:50:47, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1597, Batch std: 0.3451, Agg std: 0.3550
2025-03-04 21:28:03,466 - sim - INFO - Epoch [1][7600/40500]	lr: 8.000e-04, eta: 5:50:43, time: 0.041, data_time: 0.013, memory: 360, loss: 0.1544, Batch std: 0.3394, Agg std: 0.3548
2025-03-04 21:28:07,511 - sim - INFO - Epoch [1][7700/40500]	lr: 8.000e-04, eta: 5:50:38, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1469, Batch std: 0.3324, Agg std: 0.3546
2025-03-04 21:28:11,505 - sim - INFO - Epoch [1][7800/40500]	lr: 8.000e-04, eta: 5:50:30, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1637, Batch std: 0.3496, Agg std: 0.3544
2025-03-04 21:28:15,453 - sim - INFO - Epoch [1][7900/40500]	lr: 8.000e-04, eta: 5:50:19, time: 0.039, data_time: 0.011, memory: 360, loss: 0.1590, Batch std: 0.3440, Agg std: 0.3543
2025-03-04 21:28:19,418 - sim - INFO - Epoch [1][8000/40500]	lr: 8.000e-04, eta: 5:50:09, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1555, Batch std: 0.3451, Agg std: 0.3542
2025-03-04 21:28:23,428 - sim - INFO - Epoch [1][8100/40500]	lr: 8.000e-04, eta: 5:50:02, time: 0.040, data_time: 0.012, memory: 360, loss: 0.1538, Batch std: 0.3403, Agg std: 0.3541

2025-05-08 07:34:35,178 - sim - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda-11.3
NVCC: Cuda compilation tools, release 11.3, V11.3.109
GCC: gcc (Ubuntu 6.5.0-2ubuntu1~16.04) 6.5.0 20181026
PyTorch: 1.12.1
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1
OpenCV: 4.10.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
Simulation: 0.7.0+1c0e386
------------------------------------------------------------

2025-05-08 07:34:35,179 - sim - INFO - Distributed training: False
2025-05-08 07:34:35,334 - sim - INFO - Config:
model = dict(
    type='ParticleSimulator',
    backbone=dict(
        type='TPI',
        attr_dim=7,
        state_dim=6,
        position_dim=3,
        embed_dims=128,
        num_heads=8,
        num_encoder_layers=4,
        order=('selfattn', 'norm', 'ffn', 'norm')),
    head=dict(
        type='ParticleHead',
        in_channels=128,
        out_channels=3,
        seperate=False,
        rotation_dim=4,
        weighted=False,
        loss=dict(type='MSELoss', loss_weight=1.0)))
dataset_type = 'PhysicsFleXDataset'
pstep = 2
env_cfg = dict(
    gen_data=False,
    scene_params=[0.25, 0.25, 0.25, 0.25, 0, 8, 15, 8],
    env='BoxBath',
    hierarchy=False,
    num_abs_token=0,
    eval_ratio=10000000.0,
    dataf='./data/data_BoxBath',
    n_rollout=3000,
    time_step=151,
    time_step_clip=0,
    attn_mask=8,
    dt=0.016666666666666666,
    nf_relation=300,
    nf_particle=200,
    nf_effect=200,
    train_valid_ratio=0.9,
    n_instance=2,
    n_stages=4,
    n_his=0,
    shape_state_dim=14,
    attr_dim=7,
    state_dim=6,
    position_dim=3,
    relation_dim=1,
    pstep=2,
    neighbor_radius=0.08,
    phases_dict=dict(
        instance_idx=[0, 64, 1024],
        root_num=[[8], []],
        root_sib_radius=[[0.4], []],
        root_des_radius=[[0.08], []],
        root_pstep=[[2], []],
        instance=['cube', 'fluid'],
        material=['rigid', 'fluid']))
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=8,
    train=dict(
        type='PhysicsFleXDataset',
        phase='train',
        env_cfg=dict(
            gen_data=False,
            scene_params=[0.25, 0.25, 0.25, 0.25, 0, 8, 15, 8],
            env='BoxBath',
            hierarchy=False,
            num_abs_token=0,
            eval_ratio=10000000.0,
            dataf='./data/data_BoxBath',
            n_rollout=3000,
            time_step=151,
            time_step_clip=0,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=2,
            n_stages=4,
            n_his=0,
            shape_state_dim=14,
            attr_dim=7,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            pstep=2,
            neighbor_radius=0.08,
            phases_dict=dict(
                instance_idx=[0, 64, 1024],
                root_num=[[8], []],
                root_sib_radius=[[0.4], []],
                root_des_radius=[[0.08], []],
                root_pstep=[[2], []],
                instance=['cube', 'fluid'],
                material=['rigid', 'fluid'])),
        verbose=False),
    val=dict(
        type='PhysicsFleXDataset',
        phase='valid',
        env_cfg=dict(
            gen_data=False,
            scene_params=[0.25, 0.25, 0.25, 0.25, 0, 8, 15, 8],
            env='BoxBath',
            hierarchy=False,
            num_abs_token=0,
            eval_ratio=10000000.0,
            dataf='./data/data_BoxBath',
            n_rollout=3000,
            time_step=151,
            time_step_clip=0,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=2,
            n_stages=4,
            n_his=0,
            shape_state_dim=14,
            attr_dim=7,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            pstep=2,
            neighbor_radius=0.08,
            phases_dict=dict(
                instance_idx=[0, 64, 1024],
                root_num=[[8], []],
                root_sib_radius=[[0.4], []],
                root_des_radius=[[0.08], []],
                root_pstep=[[2], []],
                instance=['cube', 'fluid'],
                material=['rigid', 'fluid'])),
        verbose=False),
    test=dict(
        type='PhysicsFleXDataset',
        phase='valid',
        env_cfg=dict(
            gen_data=False,
            scene_params=[0.25, 0.25, 0.25, 0.25, 0, 8, 15, 8],
            env='BoxBath',
            hierarchy=False,
            num_abs_token=0,
            eval_ratio=10000000.0,
            dataf='./data/data_BoxBath',
            n_rollout=3000,
            time_step=151,
            time_step_clip=0,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=2,
            n_stages=4,
            n_his=0,
            shape_state_dim=14,
            attr_dim=7,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            pstep=2,
            neighbor_radius=0.08,
            phases_dict=dict(
                instance_idx=[0, 64, 1024],
                root_num=[[8], []],
                root_sib_radius=[[0.4], []],
                root_des_radius=[[0.08], []],
                root_pstep=[[2], []],
                instance=['cube', 'fluid'],
                material=['rigid', 'fluid'])),
        verbose=False))
optimizer = dict(
    type='Adam', lr=0.0008, betas=(0.9, 0.999), weight_decay=0, amsgrad=False)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='Plateau', mode='min', factor=0.8, patience=3)
runner = dict(type='EpochBasedRunner', max_epochs=5)
checkpoint_config = dict(interval=1)
log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl', port='29511')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
find_unused_parameters = True
work_dir = 'work_dirs/tpi_boxbath/'
gpu_ids = range(0, 1)

2025-05-08 07:34:35,349 - sim - INFO - Model parameters: 2409735
2025-05-08 07:34:36,107 - sim - INFO - Start running, host: zbl@lab601-2, work_dir: /home/zbl/sim/TIE_ECCV2022/work_dirs/tpi_boxbath
2025-05-08 07:34:36,107 - sim - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(NORMAL      ) MSEAccuracy                        
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) MSEAccuracy                        
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-05-08 07:34:36,107 - sim - INFO - workflow: [('train', 1)], max: 5 epochs
2025-05-08 07:34:36,107 - sim - INFO - Checkpoints will be saved to /home/zbl/sim/TIE_ECCV2022/work_dirs/tpi_boxbath by HardDiskBackend.
2025-05-08 07:34:44,365 - sim - INFO - Epoch [1][100/202500]	lr: 8.000e-04, eta: 23:11:08, time: 0.082, data_time: 0.048, memory: 1138, loss: 1.9966, Batch std: 1.0734, Agg std: 1.5805
2025-05-08 07:34:48,886 - sim - INFO - Epoch [1][200/202500]	lr: 8.000e-04, eta: 17:56:47, time: 0.045, data_time: 0.014, memory: 1138, loss: 0.8771, Batch std: 0.7759, Agg std: 0.9664
2025-05-08 07:34:53,272 - sim - INFO - Epoch [1][300/202500]	lr: 8.000e-04, eta: 16:04:23, time: 0.044, data_time: 0.011, memory: 1138, loss: 0.9983, Batch std: 0.8484, Agg std: 0.9117
2025-05-08 07:34:57,585 - sim - INFO - Epoch [1][400/202500]	lr: 8.000e-04, eta: 15:04:56, time: 0.043, data_time: 0.009, memory: 1138, loss: 0.9808, Batch std: 0.8294, Agg std: 0.8858
2025-05-08 07:35:02,533 - sim - INFO - Epoch [1][500/202500]	lr: 8.000e-04, eta: 14:50:55, time: 0.050, data_time: 0.016, memory: 1138, loss: 1.1296, Batch std: 0.9132, Agg std: 0.8854
2025-05-08 07:35:10,043 - sim - INFO - Epoch [1][600/202500]	lr: 8.000e-04, eta: 15:53:25, time: 0.075, data_time: 0.041, memory: 1138, loss: 0.9204, Batch std: 0.8088, Agg std: 0.8829
2025-05-08 07:35:16,073 - sim - INFO - Epoch [1][700/202500]	lr: 8.000e-04, eta: 16:02:18, time: 0.060, data_time: 0.027, memory: 1138, loss: 0.7050, Batch std: 0.7089, Agg std: 0.8635
2025-05-08 07:35:21,871 - sim - INFO - Epoch [1][800/202500]	lr: 8.000e-04, eta: 16:04:11, time: 0.058, data_time: 0.023, memory: 1138, loss: 0.4541, Batch std: 0.5676, Agg std: 0.8344
2025-05-08 07:35:28,641 - sim - INFO - Epoch [1][900/202500]	lr: 8.000e-04, eta: 16:23:49, time: 0.068, data_time: 0.032, memory: 1138, loss: 0.3213, Batch std: 0.4871, Agg std: 0.7966
2025-05-08 07:35:34,117 - sim - INFO - Epoch [1][1000/202500]	lr: 8.000e-04, eta: 16:17:34, time: 0.055, data_time: 0.020, memory: 1138, loss: 0.3163, Batch std: 0.4882, Agg std: 0.7639
2025-05-08 07:35:40,165 - sim - INFO - Epoch [1][1100/202500]	lr: 8.000e-04, eta: 16:21:22, time: 0.061, data_time: 0.026, memory: 1138, loss: 0.2320, Batch std: 0.4181, Agg std: 0.7348
2025-05-08 07:35:47,110 - sim - INFO - Epoch [1][1200/202500]	lr: 8.000e-04, eta: 16:37:02, time: 0.069, data_time: 0.034, memory: 1138, loss: 0.1518, Batch std: 0.3363, Agg std: 0.7029
2025-05-08 07:35:56,064 - sim - INFO - Epoch [1][1300/202500]	lr: 8.000e-04, eta: 17:16:16, time: 0.089, data_time: 0.054, memory: 1138, loss: 0.1459, Batch std: 0.3244, Agg std: 0.6736
2025-05-08 07:36:03,012 - sim - INFO - Epoch [1][1400/202500]	lr: 8.000e-04, eta: 17:25:51, time: 0.070, data_time: 0.034, memory: 1138, loss: 0.1555, Batch std: 0.3420, Agg std: 0.6486
2025-05-08 07:36:10,106 - sim - INFO - Epoch [1][1500/202500]	lr: 8.000e-04, eta: 17:35:42, time: 0.071, data_time: 0.035, memory: 1138, loss: 0.1233, Batch std: 0.2964, Agg std: 0.6255
2025-05-08 07:36:15,600 - sim - INFO - Epoch [1][1600/202500]	lr: 8.000e-04, eta: 17:27:25, time: 0.055, data_time: 0.018, memory: 1138, loss: 0.1557, Batch std: 0.3414, Agg std: 0.6058
2025-05-08 07:36:20,368 - sim - INFO - Epoch [1][1700/202500]	lr: 8.000e-04, eta: 17:12:57, time: 0.048, data_time: 0.007, memory: 1138, loss: 0.1327, Batch std: 0.3044, Agg std: 0.5888
2025-05-08 07:36:26,345 - sim - INFO - Epoch [1][1800/202500]	lr: 8.000e-04, eta: 17:11:26, time: 0.060, data_time: 0.021, memory: 1138, loss: 0.1282, Batch std: 0.3091, Agg std: 0.5725
2025-05-08 07:36:32,744 - sim - INFO - Epoch [1][1900/202500]	lr: 8.000e-04, eta: 17:13:45, time: 0.064, data_time: 0.027, memory: 1138, loss: 0.1493, Batch std: 0.3287, Agg std: 0.5585
2025-05-08 07:36:37,945 - sim - INFO - Epoch [1][2000/202500]	lr: 8.000e-04, eta: 17:05:45, time: 0.052, data_time: 0.014, memory: 1138, loss: 0.1275, Batch std: 0.3049, Agg std: 0.5465
2025-05-08 07:36:43,140 - sim - INFO - Epoch [1][2100/202500]	lr: 8.000e-04, eta: 16:58:27, time: 0.052, data_time: 0.012, memory: 1138, loss: 0.1476, Batch std: 0.3231, Agg std: 0.5348
2025-05-08 07:36:48,394 - sim - INFO - Epoch [1][2200/202500]	lr: 8.000e-04, eta: 16:52:19, time: 0.053, data_time: 0.013, memory: 1138, loss: 0.1319, Batch std: 0.3098, Agg std: 0.5251
2025-05-08 07:36:54,444 - sim - INFO - Epoch [1][2300/202500]	lr: 8.000e-04, eta: 16:52:26, time: 0.060, data_time: 0.024, memory: 1138, loss: 0.1158, Batch std: 0.2841, Agg std: 0.5146
2025-05-08 07:37:01,145 - sim - INFO - Epoch [1][2400/202500]	lr: 8.000e-04, eta: 16:57:10, time: 0.067, data_time: 0.029, memory: 1138, loss: 0.1146, Batch std: 0.2885, Agg std: 0.5050
2025-05-08 07:37:07,819 - sim - INFO - Epoch [1][2500/202500]	lr: 8.000e-04, eta: 17:01:21, time: 0.067, data_time: 0.029, memory: 1138, loss: 0.1366, Batch std: 0.3080, Agg std: 0.4966
2025-05-08 07:37:13,900 - sim - INFO - Epoch [1][2600/202500]	lr: 8.000e-04, eta: 17:01:17, time: 0.061, data_time: 0.021, memory: 1138, loss: 0.1263, Batch std: 0.3093, Agg std: 0.4893
2025-05-08 07:37:19,031 - sim - INFO - Epoch [1][2700/202500]	lr: 8.000e-04, eta: 16:55:21, time: 0.051, data_time: 0.008, memory: 1138, loss: 0.1101, Batch std: 0.2753, Agg std: 0.4817
2025-05-08 07:37:24,120 - sim - INFO - Epoch [1][2800/202500]	lr: 8.000e-04, eta: 16:49:36, time: 0.051, data_time: 0.008, memory: 1138, loss: 0.1300, Batch std: 0.3142, Agg std: 0.4749
2025-05-08 07:37:29,173 - sim - INFO - Epoch [1][2900/202500]	lr: 8.000e-04, eta: 16:43:59, time: 0.050, data_time: 0.006, memory: 1138, loss: 0.1476, Batch std: 0.3232, Agg std: 0.4695
2025-05-08 07:37:34,645 - sim - INFO - Epoch [1][3000/202500]	lr: 8.000e-04, eta: 16:41:07, time: 0.055, data_time: 0.015, memory: 1138, loss: 0.0967, Batch std: 0.2615, Agg std: 0.4635
2025-05-08 07:37:42,298 - sim - INFO - Epoch [1][3100/202500]	lr: 8.000e-04, eta: 16:50:15, time: 0.077, data_time: 0.039, memory: 1138, loss: 0.1252, Batch std: 0.3032, Agg std: 0.4575
2025-05-08 07:37:49,138 - sim - INFO - Epoch [1][3200/202500]	lr: 8.000e-04, eta: 16:54:33, time: 0.068, data_time: 0.030, memory: 1138, loss: 0.1162, Batch std: 0.2899, Agg std: 0.4524
2025-05-08 07:37:55,686 - sim - INFO - Epoch [1][3300/202500]	lr: 8.000e-04, eta: 16:57:05, time: 0.065, data_time: 0.027, memory: 1138, loss: 0.0970, Batch std: 0.2573, Agg std: 0.4470
2025-05-08 07:38:02,057 - sim - INFO - Epoch [1][3400/202500]	lr: 8.000e-04, eta: 16:58:35, time: 0.064, data_time: 0.022, memory: 1138, loss: 0.0969, Batch std: 0.2636, Agg std: 0.4414
2025-05-08 07:38:07,153 - sim - INFO - Epoch [1][3500/202500]	lr: 8.000e-04, eta: 16:53:50, time: 0.051, data_time: 0.007, memory: 1138, loss: 0.0999, Batch std: 0.2655, Agg std: 0.4362
2025-05-08 07:38:12,217 - sim - INFO - Epoch [1][3600/202500]	lr: 8.000e-04, eta: 16:49:15, time: 0.051, data_time: 0.005, memory: 1138, loss: 0.1033, Batch std: 0.2746, Agg std: 0.4313
2025-05-08 07:38:19,733 - sim - INFO - Epoch [1][3700/202500]	lr: 8.000e-04, eta: 16:56:02, time: 0.075, data_time: 0.036, memory: 1138, loss: 0.1074, Batch std: 0.2792, Agg std: 0.4273
2025-05-08 07:38:29,119 - sim - INFO - Epoch [1][3800/202500]	lr: 8.000e-04, eta: 17:10:43, time: 0.094, data_time: 0.054, memory: 1138, loss: 0.0968, Batch std: 0.2680, Agg std: 0.4233
2025-05-08 07:38:35,896 - sim - INFO - Epoch [1][3900/202500]	lr: 8.000e-04, eta: 17:13:25, time: 0.068, data_time: 0.031, memory: 1138, loss: 0.0998, Batch std: 0.2637, Agg std: 0.4191

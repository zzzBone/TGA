2025-01-06 18:37:03,450 - sim - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda-11.3
NVCC: Cuda compilation tools, release 11.3, V11.3.109
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~16.04) 9.4.0
PyTorch: 1.12.1
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1
OpenCV: 4.10.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
Simulation: 0.7.0+b4161dc
------------------------------------------------------------

2025-01-06 18:37:03,450 - sim - INFO - Distributed training: False
2025-01-06 18:37:03,559 - sim - INFO - Config:
model = dict(
    type='ParticleSimulator',
    backbone=dict(
        type='TGA',
        attr_dim=3,
        state_dim=6,
        position_dim=3,
        embed_dim=256,
        attn_dims=(256, 256),
        attn_num_heads=(8, 8),
        gat_hidden_dims=(256, 256),
        gat_num_heads=(8, 8),
        num_layers=2,
        dropouts=(0.0, 0.0),
        output_dim=256),
    head=dict(
        type='ParticleHead',
        in_channels=256,
        out_channels=3,
        seperate=False,
        rotation_dim=0,
        weighted=False,
        loss=dict(type='MSELoss', loss_weight=1.0)))
dataset_type = 'PhysicsFleXDataset'
env_cfg = dict(
    env='FluidFall',
    num_abs_token=0,
    baseline=False,
    gen_data=False,
    gen_meta=False,
    hierarchy=False,
    scene_params=[],
    eval_ratio=10000000.0,
    dataf='./data/data_FluidFall',
    n_rollout=100,
    time_step=121,
    time_step_clip=5,
    attn_mask=8,
    dt=0.016666666666666666,
    nf_relation=300,
    nf_particle=200,
    nf_effect=200,
    train_valid_ratio=0.9,
    n_instance=1,
    n_stages=1,
    n_his=0,
    shape_state_dim=14,
    attr_dim=3,
    state_dim=6,
    position_dim=3,
    relation_dim=1,
    neighbor_radius=0.08,
    pstep=2,
    phases_dict=dict(
        instance_idx=[0, 189],
        root_num=[[]],
        instance=['fluid'],
        material=['fluid']))
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=8,
    train=dict(
        type='PhysicsFleXDataset',
        phase='train',
        env_cfg=dict(
            env='FluidFall',
            num_abs_token=0,
            baseline=False,
            gen_data=False,
            gen_meta=False,
            hierarchy=False,
            scene_params=[],
            eval_ratio=10000000.0,
            dataf='./data/data_FluidFall',
            n_rollout=100,
            time_step=121,
            time_step_clip=5,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=1,
            n_stages=1,
            n_his=0,
            shape_state_dim=14,
            attr_dim=3,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            neighbor_radius=0.08,
            pstep=2,
            phases_dict=dict(
                instance_idx=[0, 189],
                root_num=[[]],
                instance=['fluid'],
                material=['fluid'])),
        verbose=False),
    val=dict(
        type='PhysicsFleXDataset',
        phase='valid',
        env_cfg=dict(
            env='FluidFall',
            num_abs_token=0,
            baseline=False,
            gen_data=False,
            gen_meta=False,
            hierarchy=False,
            scene_params=[],
            eval_ratio=10000000.0,
            dataf='./data/data_FluidFall',
            n_rollout=100,
            time_step=121,
            time_step_clip=5,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=1,
            n_stages=1,
            n_his=0,
            shape_state_dim=14,
            attr_dim=3,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            neighbor_radius=0.08,
            pstep=2,
            phases_dict=dict(
                instance_idx=[0, 189],
                root_num=[[]],
                instance=['fluid'],
                material=['fluid'])),
        verbose=False),
    test=dict(
        type='PhysicsFleXDataset',
        phase='valid',
        env_cfg=dict(
            env='FluidFall',
            num_abs_token=0,
            baseline=False,
            gen_data=False,
            gen_meta=False,
            hierarchy=False,
            scene_params=[],
            eval_ratio=10000000.0,
            dataf='./data/data_FluidFall',
            n_rollout=100,
            time_step=121,
            time_step_clip=5,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=1,
            n_stages=1,
            n_his=0,
            shape_state_dim=14,
            attr_dim=3,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            neighbor_radius=0.08,
            pstep=2,
            phases_dict=dict(
                instance_idx=[0, 189],
                root_num=[[]],
                instance=['fluid'],
                material=['fluid'])),
        verbose=False))
optimizer = dict(
    type='Adam', lr=0.0008, betas=(0.9, 0.999), weight_decay=0, amsgrad=False)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='Plateau', mode='min', factor=0.8, patience=3)
runner = dict(type='EpochBasedRunner', max_epochs=13)
checkpoint_config = dict(interval=1)
log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl', port='29513')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
find_unused_parameters = True
work_dir = 'work_dirs/tga_test_fluidfall/'
gpu_ids = range(0, 1)

2025-01-06 18:37:03,593 - sim - INFO - Model parameters: 878915
2025-01-06 18:37:04,322 - sim - INFO - Start running, host: zbl@lab601-2, work_dir: /home/zbl/sim/TIE_ECCV2022/work_dirs/tga_test_fluidfall
2025-01-06 18:37:04,322 - sim - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(NORMAL      ) MSEAccuracy                        
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) MSEAccuracy                        
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-01-06 18:37:04,323 - sim - INFO - workflow: [('train', 1)], max: 13 epochs
2025-01-06 18:37:04,323 - sim - INFO - Checkpoints will be saved to /home/zbl/sim/TIE_ECCV2022/work_dirs/tga_test_fluidfall by HardDiskBackend.
2025-01-06 18:37:11,070 - sim - INFO - Epoch [1][100/1350]	lr: 8.000e-04, eta: 0:19:37, time: 0.067, data_time: 0.051, memory: 103, loss: 0.3099, Batch std: 0.4733, Agg std: 0.6032
2025-01-06 18:37:14,904 - sim - INFO - Epoch [1][200/1350]	lr: 8.000e-04, eta: 0:15:17, time: 0.038, data_time: 0.026, memory: 103, loss: 0.1863, Batch std: 0.3690, Agg std: 0.4411
2025-01-06 18:37:18,944 - sim - INFO - Epoch [1][300/1350]	lr: 8.000e-04, eta: 0:14:00, time: 0.040, data_time: 0.028, memory: 103, loss: 0.1926, Batch std: 0.3740, Agg std: 0.4107
2025-01-06 18:37:22,729 - sim - INFO - Epoch [1][400/1350]	lr: 8.000e-04, eta: 0:13:09, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1787, Batch std: 0.3640, Agg std: 0.4003
2025-01-06 18:37:26,665 - sim - INFO - Epoch [1][500/1350]	lr: 8.000e-04, eta: 0:12:41, time: 0.039, data_time: 0.027, memory: 103, loss: 0.1906, Batch std: 0.3705, Agg std: 0.3930
2025-01-06 18:37:30,466 - sim - INFO - Epoch [1][600/1350]	lr: 8.000e-04, eta: 0:12:18, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1883, Batch std: 0.3672, Agg std: 0.3887
2025-01-06 18:37:34,480 - sim - INFO - Epoch [1][700/1350]	lr: 8.000e-04, eta: 0:12:05, time: 0.040, data_time: 0.027, memory: 103, loss: 0.1723, Batch std: 0.3539, Agg std: 0.3832
2025-01-06 18:37:38,252 - sim - INFO - Epoch [1][800/1350]	lr: 8.000e-04, eta: 0:11:50, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1969, Batch std: 0.3770, Agg std: 0.3817
2025-01-06 18:37:42,202 - sim - INFO - Epoch [1][900/1350]	lr: 8.000e-04, eta: 0:11:40, time: 0.040, data_time: 0.027, memory: 103, loss: 0.1811, Batch std: 0.3658, Agg std: 0.3803
2025-01-06 18:37:45,988 - sim - INFO - Epoch [1][1000/1350]	lr: 8.000e-04, eta: 0:11:29, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1948, Batch std: 0.3761, Agg std: 0.3792
2025-01-06 18:37:49,956 - sim - INFO - Epoch [1][1100/1350]	lr: 8.000e-04, eta: 0:11:22, time: 0.040, data_time: 0.027, memory: 103, loss: 0.1758, Batch std: 0.3572, Agg std: 0.3784
2025-01-06 18:37:53,784 - sim - INFO - Epoch [1][1200/1350]	lr: 8.000e-04, eta: 0:11:13, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1758, Batch std: 0.3560, Agg std: 0.3761
2025-01-06 18:37:57,727 - sim - INFO - Epoch [1][1300/1350]	lr: 8.000e-04, eta: 0:11:07, time: 0.039, data_time: 0.027, memory: 103, loss: 0.1743, Batch std: 0.3633, Agg std: 0.3750
2025-01-06 18:37:59,480 - sim - INFO - Saving checkpoint at 1 epochs
2025-01-06 18:38:05,991 - sim - INFO - Epoch(val) [1][1350]	pos mse mean: 2.8915, pos mse std: 0.1152, vel mean: 0.35931140184402466, vel std: 0.21474876999855042, eval ratio: 10000000.0000
2025-01-06 18:38:12,669 - sim - INFO - Epoch [2][100/1350]	lr: 8.000e-04, eta: 0:11:07, time: 0.067, data_time: 0.054, memory: 103, loss: 0.1934, Batch std: 0.3725, Agg std: 0.3082
2025-01-06 18:38:16,457 - sim - INFO - Epoch [2][200/1350]	lr: 8.000e-04, eta: 0:10:59, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1974, Batch std: 0.3772, Agg std: 0.3121
2025-01-06 18:38:20,414 - sim - INFO - Epoch [2][300/1350]	lr: 8.000e-04, eta: 0:10:53, time: 0.040, data_time: 0.027, memory: 103, loss: 0.1735, Batch std: 0.3598, Agg std: 0.3152
2025-01-06 18:38:24,266 - sim - INFO - Epoch [2][400/1350]	lr: 8.000e-04, eta: 0:10:47, time: 0.039, data_time: 0.026, memory: 103, loss: 0.1666, Batch std: 0.3514, Agg std: 0.3171
2025-01-06 18:38:28,264 - sim - INFO - Epoch [2][500/1350]	lr: 8.000e-04, eta: 0:10:42, time: 0.040, data_time: 0.027, memory: 103, loss: 0.1774, Batch std: 0.3608, Agg std: 0.3189
2025-01-06 18:38:32,352 - sim - INFO - Epoch [2][600/1350]	lr: 8.000e-04, eta: 0:10:38, time: 0.041, data_time: 0.027, memory: 103, loss: 0.1774, Batch std: 0.3613, Agg std: 0.3210
2025-01-06 18:38:36,531 - sim - INFO - Epoch [2][700/1350]	lr: 8.000e-04, eta: 0:10:34, time: 0.042, data_time: 0.025, memory: 103, loss: 0.1876, Batch std: 0.3669, Agg std: 0.3227
2025-01-06 18:38:40,736 - sim - INFO - Epoch [2][800/1350]	lr: 8.000e-04, eta: 0:10:31, time: 0.042, data_time: 0.024, memory: 103, loss: 0.1761, Batch std: 0.3582, Agg std: 0.3245
2025-01-06 18:38:44,695 - sim - INFO - Epoch [2][900/1350]	lr: 8.000e-04, eta: 0:10:26, time: 0.040, data_time: 0.023, memory: 103, loss: 0.1815, Batch std: 0.3622, Agg std: 0.3259
2025-01-06 18:38:48,985 - sim - INFO - Epoch [2][1000/1350]	lr: 8.000e-04, eta: 0:10:23, time: 0.043, data_time: 0.024, memory: 103, loss: 0.1619, Batch std: 0.3455, Agg std: 0.3271
2025-01-06 18:38:52,836 - sim - INFO - Epoch [2][1100/1350]	lr: 8.000e-04, eta: 0:10:17, time: 0.039, data_time: 0.022, memory: 103, loss: 0.1758, Batch std: 0.3568, Agg std: 0.3279
2025-01-06 18:38:56,748 - sim - INFO - Epoch [2][1200/1350]	lr: 8.000e-04, eta: 0:10:12, time: 0.039, data_time: 0.025, memory: 103, loss: 0.1850, Batch std: 0.3650, Agg std: 0.3291
2025-01-06 18:39:00,649 - sim - INFO - Epoch [2][1300/1350]	lr: 8.000e-04, eta: 0:10:07, time: 0.039, data_time: 0.026, memory: 103, loss: 0.1636, Batch std: 0.3486, Agg std: 0.3300
2025-01-06 18:39:02,578 - sim - INFO - Saving checkpoint at 2 epochs
2025-01-06 18:39:09,088 - sim - INFO - Epoch(val) [2][1350]	pos mse mean: 2.6158, pos mse std: 0.1461, vel mean: 0.3489459455013275, vel std: 0.2118624448776245, eval ratio: 10000000.0000
2025-01-06 18:39:15,691 - sim - INFO - Epoch [3][100/1350]	lr: 8.000e-04, eta: 0:10:03, time: 0.066, data_time: 0.053, memory: 103, loss: 0.1789, Batch std: 0.3598, Agg std: 0.3015
2025-01-06 18:39:19,623 - sim - INFO - Epoch [3][200/1350]	lr: 8.000e-04, eta: 0:09:59, time: 0.039, data_time: 0.026, memory: 103, loss: 0.1753, Batch std: 0.3617, Agg std: 0.3033
2025-01-06 18:39:23,663 - sim - INFO - Epoch [3][300/1350]	lr: 8.000e-04, eta: 0:09:54, time: 0.040, data_time: 0.028, memory: 103, loss: 0.1720, Batch std: 0.3515, Agg std: 0.3048
2025-01-06 18:39:27,443 - sim - INFO - Epoch [3][400/1350]	lr: 8.000e-04, eta: 0:09:49, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1825, Batch std: 0.3675, Agg std: 0.3063
2025-01-06 18:39:31,381 - sim - INFO - Epoch [3][500/1350]	lr: 8.000e-04, eta: 0:09:44, time: 0.039, data_time: 0.027, memory: 103, loss: 0.1802, Batch std: 0.3628, Agg std: 0.3078
2025-01-06 18:39:35,291 - sim - INFO - Epoch [3][600/1350]	lr: 8.000e-04, eta: 0:09:39, time: 0.039, data_time: 0.026, memory: 103, loss: 0.1741, Batch std: 0.3532, Agg std: 0.3090
2025-01-06 18:39:39,287 - sim - INFO - Epoch [3][700/1350]	lr: 8.000e-04, eta: 0:09:35, time: 0.040, data_time: 0.027, memory: 103, loss: 0.1754, Batch std: 0.3610, Agg std: 0.3102
2025-01-06 18:39:43,177 - sim - INFO - Epoch [3][800/1350]	lr: 8.000e-04, eta: 0:09:30, time: 0.039, data_time: 0.026, memory: 103, loss: 0.1790, Batch std: 0.3632, Agg std: 0.3116
2025-01-06 18:39:47,110 - sim - INFO - Epoch [3][900/1350]	lr: 8.000e-04, eta: 0:09:26, time: 0.039, data_time: 0.026, memory: 103, loss: 0.1672, Batch std: 0.3485, Agg std: 0.3127
2025-01-06 18:39:51,051 - sim - INFO - Epoch [3][1000/1350]	lr: 8.000e-04, eta: 0:09:21, time: 0.039, data_time: 0.027, memory: 103, loss: 0.1804, Batch std: 0.3623, Agg std: 0.3135
2025-01-06 18:39:54,942 - sim - INFO - Epoch [3][1100/1350]	lr: 8.000e-04, eta: 0:09:16, time: 0.039, data_time: 0.026, memory: 103, loss: 0.1755, Batch std: 0.3562, Agg std: 0.3148
2025-01-06 18:39:58,888 - sim - INFO - Epoch [3][1200/1350]	lr: 8.000e-04, eta: 0:09:12, time: 0.039, data_time: 0.027, memory: 103, loss: 0.1713, Batch std: 0.3555, Agg std: 0.3156
2025-01-06 18:40:02,735 - sim - INFO - Epoch [3][1300/1350]	lr: 8.000e-04, eta: 0:09:07, time: 0.038, data_time: 0.026, memory: 103, loss: 0.1617, Batch std: 0.3474, Agg std: 0.3164
2025-01-06 18:40:04,633 - sim - INFO - Saving checkpoint at 3 epochs
2025-01-06 18:40:11,126 - sim - INFO - Epoch(val) [3][1350]	pos mse mean: 2.6279, pos mse std: 0.1306, vel mean: 0.346318781375885, vel std: 0.21185879409313202, eval ratio: 10000000.0000
2025-01-06 18:40:17,740 - sim - INFO - Epoch [4][100/1350]	lr: 8.000e-04, eta: 0:09:03, time: 0.066, data_time: 0.053, memory: 103, loss: 0.1843, Batch std: 0.3704, Agg std: 0.2985
2025-01-06 18:40:21,538 - sim - INFO - Epoch [4][200/1350]	lr: 8.000e-04, eta: 0:08:58, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1606, Batch std: 0.3426, Agg std: 0.2997
2025-01-06 18:40:25,636 - sim - INFO - Epoch [4][300/1350]	lr: 8.000e-04, eta: 0:08:54, time: 0.041, data_time: 0.028, memory: 103, loss: 0.1821, Batch std: 0.3684, Agg std: 0.3008
2025-01-06 18:40:29,460 - sim - INFO - Epoch [4][400/1350]	lr: 8.000e-04, eta: 0:08:49, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1708, Batch std: 0.3528, Agg std: 0.3018
2025-01-06 18:40:33,426 - sim - INFO - Epoch [4][500/1350]	lr: 8.000e-04, eta: 0:08:45, time: 0.040, data_time: 0.027, memory: 103, loss: 0.1783, Batch std: 0.3617, Agg std: 0.3029
2025-01-06 18:40:37,243 - sim - INFO - Epoch [4][600/1350]	lr: 8.000e-04, eta: 0:08:41, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1787, Batch std: 0.3585, Agg std: 0.3039
2025-01-06 18:40:41,340 - sim - INFO - Epoch [4][700/1350]	lr: 8.000e-04, eta: 0:08:37, time: 0.041, data_time: 0.028, memory: 103, loss: 0.1767, Batch std: 0.3602, Agg std: 0.3048
2025-01-06 18:40:45,138 - sim - INFO - Epoch [4][800/1350]	lr: 8.000e-04, eta: 0:08:32, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1763, Batch std: 0.3560, Agg std: 0.3059
2025-01-06 18:40:49,192 - sim - INFO - Epoch [4][900/1350]	lr: 8.000e-04, eta: 0:08:28, time: 0.041, data_time: 0.028, memory: 103, loss: 0.1629, Batch std: 0.3466, Agg std: 0.3066
2025-01-06 18:40:52,950 - sim - INFO - Epoch [4][1000/1350]	lr: 8.000e-04, eta: 0:08:23, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1603, Batch std: 0.3435, Agg std: 0.3073
2025-01-06 18:40:56,956 - sim - INFO - Epoch [4][1100/1350]	lr: 8.000e-04, eta: 0:08:19, time: 0.040, data_time: 0.027, memory: 103, loss: 0.1732, Batch std: 0.3591, Agg std: 0.3080
2025-01-06 18:41:00,787 - sim - INFO - Epoch [4][1200/1350]	lr: 8.000e-04, eta: 0:08:15, time: 0.038, data_time: 0.025, memory: 103, loss: 0.1685, Batch std: 0.3487, Agg std: 0.3088
2025-01-06 18:41:04,902 - sim - INFO - Epoch [4][1300/1350]	lr: 8.000e-04, eta: 0:08:11, time: 0.041, data_time: 0.028, memory: 103, loss: 0.1619, Batch std: 0.3460, Agg std: 0.3094
2025-01-06 18:41:06,653 - sim - INFO - Saving checkpoint at 4 epochs
2025-01-06 18:41:13,297 - sim - INFO - Epoch(val) [4][1350]	pos mse mean: 2.5926, pos mse std: 0.1106, vel mean: 0.34827879071235657, vel std: 0.2086939662694931, eval ratio: 10000000.0000
2025-01-06 18:41:19,958 - sim - INFO - Epoch [5][100/1350]	lr: 8.000e-04, eta: 0:08:06, time: 0.067, data_time: 0.054, memory: 103, loss: 0.1827, Batch std: 0.3675, Agg std: 0.2965
2025-01-06 18:41:23,855 - sim - INFO - Epoch [5][200/1350]	lr: 8.000e-04, eta: 0:08:02, time: 0.039, data_time: 0.026, memory: 103, loss: 0.1701, Batch std: 0.3545, Agg std: 0.2975
2025-01-06 18:41:27,827 - sim - INFO - Epoch [5][300/1350]	lr: 8.000e-04, eta: 0:07:58, time: 0.040, data_time: 0.027, memory: 103, loss: 0.1657, Batch std: 0.3448, Agg std: 0.2982
2025-01-06 18:41:31,702 - sim - INFO - Epoch [5][400/1350]	lr: 8.000e-04, eta: 0:07:53, time: 0.039, data_time: 0.026, memory: 103, loss: 0.1759, Batch std: 0.3580, Agg std: 0.2990
2025-01-06 18:41:35,920 - sim - INFO - Epoch [5][500/1350]	lr: 8.000e-04, eta: 0:07:50, time: 0.042, data_time: 0.027, memory: 103, loss: 0.1633, Batch std: 0.3446, Agg std: 0.2997
2025-01-06 18:41:39,956 - sim - INFO - Epoch [5][600/1350]	lr: 8.000e-04, eta: 0:07:46, time: 0.040, data_time: 0.023, memory: 103, loss: 0.1689, Batch std: 0.3514, Agg std: 0.3004
2025-01-06 18:41:44,190 - sim - INFO - Epoch [5][700/1350]	lr: 8.000e-04, eta: 0:07:42, time: 0.042, data_time: 0.027, memory: 103, loss: 0.1753, Batch std: 0.3595, Agg std: 0.3011
2025-01-06 18:41:48,235 - sim - INFO - Epoch [5][800/1350]	lr: 8.000e-04, eta: 0:07:38, time: 0.040, data_time: 0.024, memory: 103, loss: 0.1794, Batch std: 0.3571, Agg std: 0.3020
2025-01-06 18:41:52,336 - sim - INFO - Epoch [5][900/1350]	lr: 8.000e-04, eta: 0:07:34, time: 0.041, data_time: 0.024, memory: 103, loss: 0.1719, Batch std: 0.3571, Agg std: 0.3027
2025-01-06 18:41:56,229 - sim - INFO - Epoch [5][1000/1350]	lr: 8.000e-04, eta: 0:07:30, time: 0.039, data_time: 0.025, memory: 103, loss: 0.1789, Batch std: 0.3620, Agg std: 0.3034
2025-01-06 18:42:00,427 - sim - INFO - Epoch [5][1100/1350]	lr: 8.000e-04, eta: 0:07:26, time: 0.042, data_time: 0.029, memory: 103, loss: 0.1633, Batch std: 0.3473, Agg std: 0.3041
2025-01-06 18:42:04,436 - sim - INFO - Epoch [5][1200/1350]	lr: 8.000e-04, eta: 0:07:22, time: 0.040, data_time: 0.025, memory: 103, loss: 0.1665, Batch std: 0.3500, Agg std: 0.3047
2025-01-06 18:42:08,626 - sim - INFO - Epoch [5][1300/1350]	lr: 8.000e-04, eta: 0:07:18, time: 0.042, data_time: 0.025, memory: 103, loss: 0.1723, Batch std: 0.3544, Agg std: 0.3053
2025-01-06 18:42:10,500 - sim - INFO - Saving checkpoint at 5 epochs
2025-01-06 18:42:17,005 - sim - INFO - Epoch(val) [5][1350]	pos mse mean: 2.5107, pos mse std: 0.1407, vel mean: 0.3494836390018463, vel std: 0.20952089130878448, eval ratio: 10000000.0000
2025-01-06 18:42:23,707 - sim - INFO - Epoch [6][100/1350]	lr: 8.000e-04, eta: 0:07:13, time: 0.067, data_time: 0.053, memory: 103, loss: 0.1768, Batch std: 0.3617, Agg std: 0.2951
2025-01-06 18:42:27,883 - sim - INFO - Epoch [6][200/1350]	lr: 8.000e-04, eta: 0:07:09, time: 0.042, data_time: 0.026, memory: 103, loss: 0.1817, Batch std: 0.3641, Agg std: 0.2959
2025-01-06 18:42:32,000 - sim - INFO - Epoch [6][300/1350]	lr: 8.000e-04, eta: 0:07:05, time: 0.041, data_time: 0.024, memory: 103, loss: 0.1677, Batch std: 0.3533, Agg std: 0.2966
2025-01-06 18:42:35,988 - sim - INFO - Epoch [6][400/1350]	lr: 8.000e-04, eta: 0:07:01, time: 0.040, data_time: 0.023, memory: 103, loss: 0.1698, Batch std: 0.3533, Agg std: 0.2973
2025-01-06 18:42:40,145 - sim - INFO - Epoch [6][500/1350]	lr: 8.000e-04, eta: 0:06:57, time: 0.042, data_time: 0.027, memory: 103, loss: 0.1564, Batch std: 0.3411, Agg std: 0.2979
2025-01-06 18:42:44,213 - sim - INFO - Epoch [6][600/1350]	lr: 8.000e-04, eta: 0:06:53, time: 0.041, data_time: 0.026, memory: 103, loss: 0.1598, Batch std: 0.3450, Agg std: 0.2983
2025-01-06 18:42:48,196 - sim - INFO - Epoch [6][700/1350]	lr: 8.000e-04, eta: 0:06:49, time: 0.040, data_time: 0.027, memory: 103, loss: 0.1759, Batch std: 0.3562, Agg std: 0.2990
2025-01-06 18:42:52,100 - sim - INFO - Epoch [6][800/1350]	lr: 8.000e-04, eta: 0:06:45, time: 0.039, data_time: 0.026, memory: 103, loss: 0.1749, Batch std: 0.3550, Agg std: 0.2996

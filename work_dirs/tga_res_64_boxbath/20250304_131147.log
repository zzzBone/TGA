2025-03-04 13:11:47,509 - sim - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda-11.3
NVCC: Cuda compilation tools, release 11.3, V11.3.109
GCC: gcc (Ubuntu 6.5.0-2ubuntu1~16.04) 6.5.0 20181026
PyTorch: 1.12.1
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1
OpenCV: 4.10.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
Simulation: 0.7.0+1227d7e
------------------------------------------------------------

2025-03-04 13:11:47,509 - sim - INFO - Distributed training: False
2025-03-04 13:11:47,679 - sim - INFO - Config:
model = dict(
    type='ParticleSimulator',
    backbone=dict(
        type='TGA',
        attr_dim=7,
        state_dim=6,
        position_dim=3,
        embed_dim=64,
        attn_dims=(64, 64),
        attn_num_heads=(8, 8),
        gat_hidden_dims=(64, 64),
        gat_num_heads=(8, 8),
        num_layers=1,
        dropouts=(0.2, 0.2),
        output_dim=64,
        num_abs_token=2),
    head=dict(
        type='ParticleHead',
        in_channels=64,
        out_channels=3,
        seperate=False,
        rotation_dim=4,
        weighted=False,
        loss=dict(type='MSELoss', loss_weight=1.0)))
dataset_type = 'PhysicsFleXDataset'
pstep = 2
env_cfg = dict(
    gen_data=False,
    scene_params=[0.25, 0.25, 0.25, 0.25, 0, 8, 15, 8],
    env='BoxBath',
    hierarchy=False,
    num_abs_token=0,
    eval_ratio=10000000.0,
    dataf='./data/data_BoxBath',
    n_rollout=3000,
    time_step=151,
    time_step_clip=0,
    attn_mask=8,
    dt=0.016666666666666666,
    nf_relation=300,
    nf_particle=200,
    nf_effect=200,
    train_valid_ratio=0.9,
    n_instance=2,
    n_stages=4,
    n_his=0,
    shape_state_dim=14,
    attr_dim=7,
    state_dim=6,
    position_dim=3,
    relation_dim=1,
    pstep=2,
    neighbor_radius=0.08,
    phases_dict=dict(
        instance_idx=[0, 64, 1024],
        root_num=[[8], []],
        root_sib_radius=[[0.4], []],
        root_des_radius=[[0.08], []],
        root_pstep=[[2], []],
        instance=['cube', 'fluid'],
        material=['rigid', 'fluid']))
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=8,
    train=dict(
        type='PhysicsFleXDataset',
        phase='train',
        env_cfg=dict(
            gen_data=False,
            scene_params=[0.25, 0.25, 0.25, 0.25, 0, 8, 15, 8],
            env='BoxBath',
            hierarchy=False,
            num_abs_token=2,
            eval_ratio=10000000.0,
            dataf='./data/data_BoxBath',
            n_rollout=3000,
            time_step=151,
            time_step_clip=0,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=2,
            n_stages=4,
            n_his=0,
            shape_state_dim=14,
            attr_dim=7,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            pstep=2,
            neighbor_radius=0.08,
            phases_dict=dict(
                instance_idx=[0, 64, 1024],
                root_num=[[8], []],
                root_sib_radius=[[0.4], []],
                root_des_radius=[[0.08], []],
                root_pstep=[[2], []],
                instance=['cube', 'fluid'],
                material=['rigid', 'fluid'])),
        verbose=False),
    val=dict(
        type='PhysicsFleXDataset',
        phase='valid',
        env_cfg=dict(
            gen_data=False,
            scene_params=[0.25, 0.25, 0.25, 0.25, 0, 8, 15, 8],
            env='BoxBath',
            hierarchy=False,
            num_abs_token=2,
            eval_ratio=10000000.0,
            dataf='./data/data_BoxBath',
            n_rollout=3000,
            time_step=151,
            time_step_clip=0,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=2,
            n_stages=4,
            n_his=0,
            shape_state_dim=14,
            attr_dim=7,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            pstep=2,
            neighbor_radius=0.08,
            phases_dict=dict(
                instance_idx=[0, 64, 1024],
                root_num=[[8], []],
                root_sib_radius=[[0.4], []],
                root_des_radius=[[0.08], []],
                root_pstep=[[2], []],
                instance=['cube', 'fluid'],
                material=['rigid', 'fluid'])),
        verbose=False),
    test=dict(
        type='PhysicsFleXDataset',
        phase='valid',
        env_cfg=dict(
            gen_data=False,
            scene_params=[0.25, 0.25, 0.25, 0.25, 0, 8, 15, 8],
            env='BoxBath',
            hierarchy=False,
            num_abs_token=2,
            eval_ratio=10000000.0,
            dataf='./data/data_BoxBath',
            n_rollout=3000,
            time_step=151,
            time_step_clip=0,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=2,
            n_stages=4,
            n_his=0,
            shape_state_dim=14,
            attr_dim=7,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            pstep=2,
            neighbor_radius=0.08,
            phases_dict=dict(
                instance_idx=[0, 64, 1024],
                root_num=[[8], []],
                root_sib_radius=[[0.4], []],
                root_des_radius=[[0.08], []],
                root_pstep=[[2], []],
                instance=['cube', 'fluid'],
                material=['rigid', 'fluid'])),
        verbose=False))
optimizer = dict(
    type='Adam', lr=0.0008, betas=(0.9, 0.999), weight_decay=0, amsgrad=False)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='Plateau', mode='min', factor=0.8, patience=3)
runner = dict(type='EpochBasedRunner', max_epochs=5)
checkpoint_config = dict(interval=1)
log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl', port='29511')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
find_unused_parameters = True
num_abs_token = 2
work_dir = 'work_dirs/tga_res_64_boxbath'
gpu_ids = range(0, 1)

2025-03-04 13:11:47,738 - sim - INFO - Model parameters: 229994
2025-03-04 13:11:48,755 - sim - INFO - Start running, host: zbl@lab601-2, work_dir: /home/zbl/sim/TIE_ECCV2022/work_dirs/tga_res_64_boxbath
2025-03-04 13:11:48,755 - sim - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(NORMAL      ) MSEAccuracy                        
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) MSEAccuracy                        
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-03-04 13:11:48,756 - sim - INFO - workflow: [('train', 1)], max: 5 epochs
2025-03-04 13:11:48,756 - sim - INFO - Checkpoints will be saved to /home/zbl/sim/TIE_ECCV2022/work_dirs/tga_res_64_boxbath by HardDiskBackend.
2025-03-04 13:12:09,010 - sim - INFO - Epoch [1][100/202500]	lr: 8.000e-04, eta: 2 days, 8:56:37, time: 0.202, data_time: 0.033, memory: 5539, loss: 1.4404, Batch std: 0.9526, Agg std: 1.3157
2025-03-04 13:12:25,342 - sim - INFO - Epoch [1][200/202500]	lr: 8.000e-04, eta: 2 days, 3:25:53, time: 0.163, data_time: 0.004, memory: 5539, loss: 0.7084, Batch std: 0.7080, Agg std: 0.8922
2025-03-04 13:12:41,663 - sim - INFO - Epoch [1][300/202500]	lr: 8.000e-04, eta: 2 days, 1:34:49, time: 0.163, data_time: 0.003, memory: 5539, loss: 0.3115, Batch std: 0.4886, Agg std: 0.7685
2025-03-04 13:12:58,308 - sim - INFO - Epoch [1][400/202500]	lr: 8.000e-04, eta: 2 days, 0:52:47, time: 0.166, data_time: 0.004, memory: 5539, loss: 0.2394, Batch std: 0.4259, Agg std: 0.6787
2025-03-04 13:13:15,478 - sim - INFO - Epoch [1][500/202500]	lr: 8.000e-04, eta: 2 days, 0:45:10, time: 0.172, data_time: 0.004, memory: 5539, loss: 0.1700, Batch std: 0.3576, Agg std: 0.6118
2025-03-04 13:13:33,309 - sim - INFO - Epoch [1][600/202500]	lr: 8.000e-04, eta: 2 days, 0:58:33, time: 0.178, data_time: 0.004, memory: 5539, loss: 0.1701, Batch std: 0.3545, Agg std: 0.5657
2025-03-04 13:13:51,427 - sim - INFO - Epoch [1][700/202500]	lr: 8.000e-04, eta: 2 days, 1:14:58, time: 0.181, data_time: 0.003, memory: 5539, loss: 0.1502, Batch std: 0.3295, Agg std: 0.5318
2025-03-04 13:14:10,173 - sim - INFO - Epoch [1][800/202500]	lr: 8.000e-04, eta: 2 days, 1:40:27, time: 0.187, data_time: 0.004, memory: 5539, loss: 0.1479, Batch std: 0.3328, Agg std: 0.5050
2025-03-04 13:14:29,326 - sim - INFO - Epoch [1][900/202500]	lr: 8.000e-04, eta: 2 days, 2:07:48, time: 0.192, data_time: 0.004, memory: 5539, loss: 0.1400, Batch std: 0.3235, Agg std: 0.4834
2025-03-04 13:14:48,847 - sim - INFO - Epoch [1][1000/202500]	lr: 8.000e-04, eta: 2 days, 2:35:48, time: 0.195, data_time: 0.004, memory: 5539, loss: 0.1274, Batch std: 0.3056, Agg std: 0.4661
2025-03-04 13:15:08,452 - sim - INFO - Epoch [1][1100/202500]	lr: 8.000e-04, eta: 2 days, 3:00:00, time: 0.196, data_time: 0.004, memory: 5539, loss: 0.1315, Batch std: 0.3072, Agg std: 0.4504
2025-03-04 13:15:27,996 - sim - INFO - Epoch [1][1200/202500]	lr: 8.000e-04, eta: 2 days, 3:19:14, time: 0.195, data_time: 0.004, memory: 5539, loss: 0.1138, Batch std: 0.3009, Agg std: 0.4380
2025-03-04 13:15:47,869 - sim - INFO - Epoch [1][1300/202500]	lr: 8.000e-04, eta: 2 days, 3:39:43, time: 0.199, data_time: 0.004, memory: 5539, loss: 0.1334, Batch std: 0.3067, Agg std: 0.4275
2025-03-04 13:16:07,695 - sim - INFO - Epoch [1][1400/202500]	lr: 8.000e-04, eta: 2 days, 3:56:40, time: 0.198, data_time: 0.004, memory: 5539, loss: 0.1227, Batch std: 0.2937, Agg std: 0.4181
2025-03-04 13:16:27,899 - sim - INFO - Epoch [1][1500/202500]	lr: 8.000e-04, eta: 2 days, 4:15:32, time: 0.202, data_time: 0.004, memory: 5539, loss: 0.1207, Batch std: 0.2894, Agg std: 0.4092
2025-03-04 13:16:48,375 - sim - INFO - Epoch [1][1600/202500]	lr: 8.000e-04, eta: 2 days, 4:34:54, time: 0.205, data_time: 0.004, memory: 5539, loss: 0.1233, Batch std: 0.2891, Agg std: 0.4015
2025-03-04 13:17:08,988 - sim - INFO - Epoch [1][1700/202500]	lr: 8.000e-04, eta: 2 days, 4:53:16, time: 0.206, data_time: 0.004, memory: 5539, loss: 0.1205, Batch std: 0.2937, Agg std: 0.3943
2025-03-04 13:17:29,987 - sim - INFO - Epoch [1][1800/202500]	lr: 8.000e-04, eta: 2 days, 5:13:12, time: 0.210, data_time: 0.004, memory: 5539, loss: 0.1325, Batch std: 0.3140, Agg std: 0.3897
2025-03-04 13:17:51,151 - sim - INFO - Epoch [1][1900/202500]	lr: 8.000e-04, eta: 2 days, 5:32:28, time: 0.212, data_time: 0.004, memory: 5539, loss: 0.0867, Batch std: 0.2457, Agg std: 0.3834
2025-03-04 13:18:12,574 - sim - INFO - Epoch [1][2000/202500]	lr: 8.000e-04, eta: 2 days, 5:51:56, time: 0.214, data_time: 0.004, memory: 5539, loss: 0.0966, Batch std: 0.2609, Agg std: 0.3766
2025-03-04 13:18:33,944 - sim - INFO - Epoch [1][2100/202500]	lr: 8.000e-04, eta: 2 days, 6:09:05, time: 0.214, data_time: 0.004, memory: 5539, loss: 0.1094, Batch std: 0.2789, Agg std: 0.3718
2025-03-04 13:18:55,755 - sim - INFO - Epoch [1][2200/202500]	lr: 8.000e-04, eta: 2 days, 6:28:01, time: 0.218, data_time: 0.004, memory: 5539, loss: 0.1150, Batch std: 0.2804, Agg std: 0.3677
2025-03-04 13:19:17,766 - sim - INFO - Epoch [1][2300/202500]	lr: 8.000e-04, eta: 2 days, 6:46:45, time: 0.220, data_time: 0.004, memory: 5539, loss: 0.1059, Batch std: 0.2721, Agg std: 0.3631
2025-03-04 13:19:39,740 - sim - INFO - Epoch [1][2400/202500]	lr: 8.000e-04, eta: 2 days, 7:03:38, time: 0.220, data_time: 0.004, memory: 5539, loss: 0.1209, Batch std: 0.2926, Agg std: 0.3597
2025-03-04 13:20:01,400 - sim - INFO - Epoch [1][2500/202500]	lr: 8.000e-04, eta: 2 days, 7:17:01, time: 0.217, data_time: 0.003, memory: 5539, loss: 0.1245, Batch std: 0.3020, Agg std: 0.3571
2025-03-04 13:20:23,551 - sim - INFO - Epoch [1][2600/202500]	lr: 8.000e-04, eta: 2 days, 7:32:32, time: 0.222, data_time: 0.004, memory: 5539, loss: 0.0846, Batch std: 0.2466, Agg std: 0.3538
2025-03-04 13:20:45,839 - sim - INFO - Epoch [1][2700/202500]	lr: 8.000e-04, eta: 2 days, 7:47:42, time: 0.223, data_time: 0.004, memory: 5539, loss: 0.1040, Batch std: 0.2701, Agg std: 0.3506
2025-03-04 13:21:08,057 - sim - INFO - Epoch [1][2800/202500]	lr: 8.000e-04, eta: 2 days, 8:01:22, time: 0.222, data_time: 0.003, memory: 5539, loss: 0.1071, Batch std: 0.2837, Agg std: 0.3478
2025-03-04 13:21:30,439 - sim - INFO - Epoch [1][2900/202500]	lr: 8.000e-04, eta: 2 days, 8:14:58, time: 0.224, data_time: 0.005, memory: 5539, loss: 0.1175, Batch std: 0.2838, Agg std: 0.3459
2025-03-04 13:21:52,701 - sim - INFO - Epoch [1][3000/202500]	lr: 8.000e-04, eta: 2 days, 8:26:59, time: 0.223, data_time: 0.004, memory: 5539, loss: 0.1188, Batch std: 0.2945, Agg std: 0.3435
2025-03-04 13:22:14,888 - sim - INFO - Epoch [1][3100/202500]	lr: 8.000e-04, eta: 2 days, 8:37:50, time: 0.222, data_time: 0.004, memory: 5539, loss: 0.1137, Batch std: 0.2848, Agg std: 0.3419
2025-03-04 13:22:37,230 - sim - INFO - Epoch [1][3200/202500]	lr: 8.000e-04, eta: 2 days, 8:48:46, time: 0.223, data_time: 0.004, memory: 5539, loss: 0.1152, Batch std: 0.2818, Agg std: 0.3400
2025-03-04 13:22:59,865 - sim - INFO - Epoch [1][3300/202500]	lr: 8.000e-04, eta: 2 days, 9:00:30, time: 0.226, data_time: 0.004, memory: 5539, loss: 0.1018, Batch std: 0.2676, Agg std: 0.3379
2025-03-04 13:23:22,147 - sim - INFO - Epoch [1][3400/202500]	lr: 8.000e-04, eta: 2 days, 9:09:47, time: 0.223, data_time: 0.003, memory: 5539, loss: 0.1023, Batch std: 0.2676, Agg std: 0.3359
2025-03-04 13:23:44,485 - sim - INFO - Epoch [1][3500/202500]	lr: 8.000e-04, eta: 2 days, 9:18:48, time: 0.223, data_time: 0.004, memory: 5539, loss: 0.0997, Batch std: 0.2656, Agg std: 0.3340
2025-03-04 13:24:06,802 - sim - INFO - Epoch [1][3600/202500]	lr: 8.000e-04, eta: 2 days, 9:27:11, time: 0.223, data_time: 0.003, memory: 5539, loss: 0.1115, Batch std: 0.2876, Agg std: 0.3324
2025-03-04 13:24:29,397 - sim - INFO - Epoch [1][3700/202500]	lr: 8.000e-04, eta: 2 days, 9:36:21, time: 0.226, data_time: 0.004, memory: 5539, loss: 0.0919, Batch std: 0.2528, Agg std: 0.3304
2025-03-04 13:24:51,921 - sim - INFO - Epoch [1][3800/202500]	lr: 8.000e-04, eta: 2 days, 9:44:42, time: 0.225, data_time: 0.004, memory: 5539, loss: 0.1065, Batch std: 0.2702, Agg std: 0.3288
2025-03-04 13:25:14,214 - sim - INFO - Epoch [1][3900/202500]	lr: 8.000e-04, eta: 2 days, 9:51:37, time: 0.223, data_time: 0.004, memory: 5539, loss: 0.0939, Batch std: 0.2507, Agg std: 0.3270
2025-03-04 13:25:36,575 - sim - INFO - Epoch [1][4000/202500]	lr: 8.000e-04, eta: 2 days, 9:58:27, time: 0.224, data_time: 0.004, memory: 5539, loss: 0.1136, Batch std: 0.2774, Agg std: 0.3254

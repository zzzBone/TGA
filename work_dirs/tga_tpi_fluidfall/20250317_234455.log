2025-03-17 23:44:55,604 - sim - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda-11.3
NVCC: Cuda compilation tools, release 11.3, V11.3.109
GCC: gcc (Ubuntu 6.5.0-2ubuntu1~16.04) 6.5.0 20181026
PyTorch: 1.12.1
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1
OpenCV: 4.10.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
Simulation: 0.7.0+1227d7e
------------------------------------------------------------

2025-03-17 23:44:55,604 - sim - INFO - Distributed training: False
2025-03-17 23:44:55,716 - sim - INFO - Config:
model = dict(
    type='ParticleSimulator',
    backbone=dict(
        type='TGA',
        attr_dim=3,
        state_dim=6,
        position_dim=3,
        embed_dim=128,
        attn_dims=(128, 128),
        attn_num_heads=(8, 8),
        gat_hidden_dims=(128, 128),
        gat_num_heads=(8, 8),
        num_layers=1,
        dropouts=(0.2, 0.2),
        output_dim=128,
        num_abs_token=2),
    head=dict(
        type='ParticleHead',
        in_channels=128,
        out_channels=3,
        seperate=False,
        rotation_dim=0,
        weighted=False,
        loss=dict(type='MSELoss', loss_weight=1.0)))
dataset_type = 'PhysicsFleXDataset'
env_cfg = dict(
    env='FluidFall',
    num_abs_token=0,
    baseline=False,
    gen_data=False,
    gen_meta=False,
    hierarchy=False,
    scene_params=[],
    eval_ratio=10000000.0,
    dataf='./data/data_FluidFall',
    n_rollout=3000,
    time_step=121,
    time_step_clip=5,
    attn_mask=8,
    dt=0.016666666666666666,
    nf_relation=300,
    nf_particle=200,
    nf_effect=200,
    train_valid_ratio=0.9,
    n_instance=1,
    n_stages=1,
    n_his=0,
    shape_state_dim=14,
    attr_dim=3,
    state_dim=6,
    position_dim=3,
    relation_dim=1,
    neighbor_radius=0.08,
    pstep=2,
    phases_dict=dict(
        instance_idx=[0, 189],
        root_num=[[]],
        instance=['fluid'],
        material=['fluid']))
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=8,
    train=dict(
        type='PhysicsFleXDataset',
        phase='train',
        env_cfg=dict(
            env='FluidFall',
            num_abs_token=2,
            baseline=False,
            gen_data=False,
            gen_meta=False,
            hierarchy=False,
            scene_params=[],
            eval_ratio=10000000.0,
            dataf='./data/data_FluidFall',
            n_rollout=3000,
            time_step=121,
            time_step_clip=5,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=1,
            n_stages=1,
            n_his=0,
            shape_state_dim=14,
            attr_dim=3,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            neighbor_radius=0.08,
            pstep=2,
            phases_dict=dict(
                instance_idx=[0, 189],
                root_num=[[]],
                instance=['fluid'],
                material=['fluid'])),
        verbose=False),
    val=dict(
        type='PhysicsFleXDataset',
        phase='valid',
        env_cfg=dict(
            env='FluidFall',
            num_abs_token=2,
            baseline=False,
            gen_data=False,
            gen_meta=False,
            hierarchy=False,
            scene_params=[],
            eval_ratio=10000000.0,
            dataf='./data/data_FluidFall',
            n_rollout=3000,
            time_step=121,
            time_step_clip=5,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=1,
            n_stages=1,
            n_his=0,
            shape_state_dim=14,
            attr_dim=3,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            neighbor_radius=0.08,
            pstep=2,
            phases_dict=dict(
                instance_idx=[0, 189],
                root_num=[[]],
                instance=['fluid'],
                material=['fluid'])),
        verbose=False),
    test=dict(
        type='PhysicsFleXDataset',
        phase='valid',
        env_cfg=dict(
            env='FluidFall',
            num_abs_token=2,
            baseline=False,
            gen_data=False,
            gen_meta=False,
            hierarchy=False,
            scene_params=[],
            eval_ratio=10000000.0,
            dataf='./data/data_FluidFall',
            n_rollout=3000,
            time_step=121,
            time_step_clip=5,
            attn_mask=8,
            dt=0.016666666666666666,
            nf_relation=300,
            nf_particle=200,
            nf_effect=200,
            train_valid_ratio=0.9,
            n_instance=1,
            n_stages=1,
            n_his=0,
            shape_state_dim=14,
            attr_dim=3,
            state_dim=6,
            position_dim=3,
            relation_dim=1,
            neighbor_radius=0.08,
            pstep=2,
            phases_dict=dict(
                instance_idx=[0, 189],
                root_num=[[]],
                instance=['fluid'],
                material=['fluid'])),
        verbose=False))
optimizer = dict(
    type='Adam', lr=0.0008, betas=(0.9, 0.999), weight_decay=0, amsgrad=False)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='Plateau', mode='min', factor=0.8, patience=3)
runner = dict(type='EpochBasedRunner', max_epochs=13)
checkpoint_config = dict(interval=1)
log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl', port='29513')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
find_unused_parameters = True
num_abs_token = 2
work_dir = 'work_dirs/tga_tpi_fluidfall/'
gpu_ids = range(0, 1)

2025-03-17 23:44:55,773 - sim - INFO - Model parameters: 871573
2025-03-17 23:44:57,459 - sim - INFO - Start running, host: zbl@lab601-2, work_dir: /home/zbl/sim/TIE_ECCV2022/work_dirs/tga_tpi_fluidfall
2025-03-17 23:44:57,459 - sim - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(NORMAL      ) MSEAccuracy                        
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PlateauLrUpdaterHook               
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) MSEAccuracy                        
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-03-17 23:44:57,460 - sim - INFO - workflow: [('train', 1)], max: 13 epochs
2025-03-17 23:44:57,460 - sim - INFO - Checkpoints will be saved to /home/zbl/sim/TIE_ECCV2022/work_dirs/tga_tpi_fluidfall by HardDiskBackend.
2025-03-17 23:45:06,598 - sim - INFO - Epoch [1][100/40500]	lr: 8.000e-04, eta: 13:21:34, time: 0.091, data_time: 0.038, memory: 1027, loss: 0.2793, Batch std: 0.4568, Agg std: 0.5475
2025-03-17 23:45:11,952 - sim - INFO - Epoch [1][200/40500]	lr: 8.000e-04, eta: 10:35:31, time: 0.054, data_time: 0.004, memory: 1027, loss: 0.1975, Batch std: 0.3821, Agg std: 0.4356
2025-03-17 23:45:18,031 - sim - INFO - Epoch [1][300/40500]	lr: 8.000e-04, eta: 10:01:17, time: 0.061, data_time: 0.011, memory: 1027, loss: 0.1858, Batch std: 0.3750, Agg std: 0.4107
2025-03-17 23:45:25,622 - sim - INFO - Epoch [1][400/40500]	lr: 8.000e-04, eta: 10:17:15, time: 0.076, data_time: 0.026, memory: 1027, loss: 0.1900, Batch std: 0.3724, Agg std: 0.4012
2025-03-17 23:45:30,902 - sim - INFO - Epoch [1][500/40500]	lr: 8.000e-04, eta: 9:46:17, time: 0.053, data_time: 0.003, memory: 1027, loss: 0.2015, Batch std: 0.3900, Agg std: 0.3968
2025-03-17 23:45:36,189 - sim - INFO - Epoch [1][600/40500]	lr: 8.000e-04, eta: 9:25:42, time: 0.053, data_time: 0.003, memory: 1027, loss: 0.1921, Batch std: 0.3789, Agg std: 0.3937
2025-03-17 23:45:41,519 - sim - INFO - Epoch [1][700/40500]	lr: 8.000e-04, eta: 9:11:31, time: 0.053, data_time: 0.004, memory: 1027, loss: 0.1756, Batch std: 0.3617, Agg std: 0.3899
2025-03-17 23:45:46,860 - sim - INFO - Epoch [1][800/40500]	lr: 8.000e-04, eta: 9:00:59, time: 0.053, data_time: 0.004, memory: 1027, loss: 0.1840, Batch std: 0.3697, Agg std: 0.3875
2025-03-17 23:45:52,144 - sim - INFO - Epoch [1][900/40500]	lr: 8.000e-04, eta: 8:52:12, time: 0.053, data_time: 0.003, memory: 1027, loss: 0.1878, Batch std: 0.3739, Agg std: 0.3854
2025-03-17 23:45:58,541 - sim - INFO - Epoch [1][1000/40500]	lr: 8.000e-04, eta: 8:54:55, time: 0.064, data_time: 0.014, memory: 1027, loss: 0.1653, Batch std: 0.3536, Agg std: 0.3821
2025-03-17 23:46:05,644 - sim - INFO - Epoch [1][1100/40500]	lr: 8.000e-04, eta: 9:02:43, time: 0.071, data_time: 0.021, memory: 1027, loss: 0.1800, Batch std: 0.3660, Agg std: 0.3805
2025-03-17 23:46:11,013 - sim - INFO - Epoch [1][1200/40500]	lr: 8.000e-04, eta: 8:56:34, time: 0.054, data_time: 0.004, memory: 1027, loss: 0.1683, Batch std: 0.3539, Agg std: 0.3791
2025-03-17 23:46:16,290 - sim - INFO - Epoch [1][1300/40500]	lr: 8.000e-04, eta: 8:50:44, time: 0.053, data_time: 0.003, memory: 1027, loss: 0.1834, Batch std: 0.3679, Agg std: 0.3772
2025-03-17 23:46:21,532 - sim - INFO - Epoch [1][1400/40500]	lr: 8.000e-04, eta: 8:45:30, time: 0.052, data_time: 0.003, memory: 1027, loss: 0.1827, Batch std: 0.3642, Agg std: 0.3768
2025-03-17 23:46:26,854 - sim - INFO - Epoch [1][1500/40500]	lr: 8.000e-04, eta: 8:41:25, time: 0.053, data_time: 0.004, memory: 1027, loss: 0.1757, Batch std: 0.3635, Agg std: 0.3757
2025-03-17 23:46:32,262 - sim - INFO - Epoch [1][1600/40500]	lr: 8.000e-04, eta: 8:38:18, time: 0.054, data_time: 0.004, memory: 1027, loss: 0.1702, Batch std: 0.3529, Agg std: 0.3744
2025-03-17 23:46:38,460 - sim - INFO - Epoch [1][1700/40500]	lr: 8.000e-04, eta: 8:39:36, time: 0.062, data_time: 0.012, memory: 1027, loss: 0.1769, Batch std: 0.3616, Agg std: 0.3734
2025-03-17 23:46:45,772 - sim - INFO - Epoch [1][1800/40500]	lr: 8.000e-04, eta: 8:46:10, time: 0.073, data_time: 0.024, memory: 1027, loss: 0.1658, Batch std: 0.3517, Agg std: 0.3725
2025-03-17 23:46:51,032 - sim - INFO - Epoch [1][1900/40500]	lr: 8.000e-04, eta: 8:42:35, time: 0.053, data_time: 0.003, memory: 1027, loss: 0.1719, Batch std: 0.3564, Agg std: 0.3716
2025-03-17 23:46:56,383 - sim - INFO - Epoch [1][2000/40500]	lr: 8.000e-04, eta: 8:39:44, time: 0.054, data_time: 0.004, memory: 1027, loss: 0.1783, Batch std: 0.3675, Agg std: 0.3713
2025-03-17 23:47:01,733 - sim - INFO - Epoch [1][2100/40500]	lr: 8.000e-04, eta: 8:37:09, time: 0.053, data_time: 0.004, memory: 1027, loss: 0.1578, Batch std: 0.3473, Agg std: 0.3706
2025-03-17 23:47:07,032 - sim - INFO - Epoch [1][2200/40500]	lr: 8.000e-04, eta: 8:34:36, time: 0.053, data_time: 0.003, memory: 1027, loss: 0.1762, Batch std: 0.3605, Agg std: 0.3697
2025-03-17 23:47:12,320 - sim - INFO - Epoch [1][2300/40500]	lr: 8.000e-04, eta: 8:32:13, time: 0.053, data_time: 0.003, memory: 1027, loss: 0.1801, Batch std: 0.3635, Agg std: 0.3693
2025-03-17 23:47:18,790 - sim - INFO - Epoch [1][2400/40500]	lr: 8.000e-04, eta: 8:34:20, time: 0.065, data_time: 0.015, memory: 1027, loss: 0.1652, Batch std: 0.3553, Agg std: 0.3686
2025-03-17 23:47:25,637 - sim - INFO - Epoch [1][2500/40500]	lr: 8.000e-04, eta: 8:37:35, time: 0.068, data_time: 0.019, memory: 1027, loss: 0.1706, Batch std: 0.3550, Agg std: 0.3683
2025-03-17 23:47:30,932 - sim - INFO - Epoch [1][2600/40500]	lr: 8.000e-04, eta: 8:35:21, time: 0.053, data_time: 0.004, memory: 1027, loss: 0.1605, Batch std: 0.3431, Agg std: 0.3676
2025-03-17 23:47:36,262 - sim - INFO - Epoch [1][2700/40500]	lr: 8.000e-04, eta: 8:33:25, time: 0.053, data_time: 0.004, memory: 1027, loss: 0.1640, Batch std: 0.3471, Agg std: 0.3668
2025-03-17 23:47:41,522 - sim - INFO - Epoch [1][2800/40500]	lr: 8.000e-04, eta: 8:31:22, time: 0.053, data_time: 0.003, memory: 1027, loss: 0.1746, Batch std: 0.3584, Agg std: 0.3662
2025-03-17 23:47:46,816 - sim - INFO - Epoch [1][2900/40500]	lr: 8.000e-04, eta: 8:29:34, time: 0.053, data_time: 0.003, memory: 1027, loss: 0.1689, Batch std: 0.3549, Agg std: 0.3659
2025-03-17 23:47:52,137 - sim - INFO - Epoch [1][3000/40500]	lr: 8.000e-04, eta: 8:27:58, time: 0.053, data_time: 0.004, memory: 1027, loss: 0.1593, Batch std: 0.3469, Agg std: 0.3653
